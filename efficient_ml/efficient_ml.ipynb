{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97fc3c50-5f36-43e0-bd46-fd0db55b47fa",
   "metadata": {},
   "source": [
    "# Efficient Model Training & Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185d5323-742a-47d0-8cb6-a4a47621bb38",
   "metadata": {},
   "source": [
    "Common problem when dealing with large datasets and working in python is a matter of efficiency in both time and space complexity. Usual solutions to combat these problems are to either increase the computing power available for the computer (which can be expense) or to continue your pipeline in a distributive framework like Spark / PySpark (which can be a hassle & expensive to set up). These sort of problems comes up often in industry settings, especially when working on problems which require you to aggregate a large amount of user data, problems associated to clustering / recommendation systems. Feeding all this data into inefficient models can be cumbersome to deal with since the computer will most likely run out of memory or it will take a lot of time to execute.\n",
    "We can solve this problem by optimizing the way we train and predict sklearn models. Instead of passing in vectors for training & predicting, we pass in sparse vectors. As you will see below that this will drastically reduce both the speed and memory used for training and predicting with the model.  \n",
    "\n",
    "### What is a Sparse Matrix?\n",
    "There are two forms of matrices, sparse and dense matrices. A matrix is sparse if majority of the elements in the matrix has zero values whereas, a matrix is dense if majority of the elements in the matrix has non zero values.  \n",
    "\n",
    "You would most commonly see sparse matrices when working with recommendation engines, encodings (for example 1-hot encoding), vectorizing etc. It's beneficial to work with sparse matrices in applied ML because it's much more efficient with both time and space complexity. It will reduce the memory necessary to store objects while making it more efficient computationally. You'll see later on that sci-kit learn is very well adept with sparse matrices and will decrease the memory and speed necessary to train and predict on large models. Operations using standard dense-matrix structures and algorithms are slow and inefficient when applied to large sparse matrices as processing and memory are wasted on the zeros [1]. Sparse data is easily compressible and requires less storage. Some very large sparse matrices are infeasible to manipulate using standard dense-matrix algorithms [1].  \n",
    "\n",
    "A matrix is generally stored as a two dimensional array. Each entry in the array represents an element which can be mapped to the row and column index in the matrix to correspond to the value in that element. For an m × n matrix, the amount of memory required to store the matrix in this format is proportional to m × n (disregarding the fact that the dimensions of the matrix also need to be stored) [1]. In the case of a sparse matrix, substantial memory requirement reductions can be realized by storing only the non-zero entries [1]. The frequency of non-zero entries in the matrix will also have an impact in saving memory and time.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62ecfc7d-39de-4279-8f8f-2554afee0395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import uuid\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0034a9-1ff3-4326-8731-4094047fcf64",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8ecf56-bde9-4a43-bad3-b055a620299b",
   "metadata": {},
   "source": [
    "We will begin by synthetically generating a dataset with a large amount of zeros using the random and pandas libraries. Through the use of the pivot_table function available in pandas we can replace all nan values in the pivot table with zeros. For the purposes of this tutorial, we'll create a DataFrame with 50,000 rows and 1,001 columns. The final column will be associated to a category, and the remaining 1,000 will be features necessary to train a classifier to predict that category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dadb441c-91ef-4039-a2a2-ed7af06388e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(id_n, prd_n):\n",
    "    '''\n",
    "    This function will generate a dataframe with a lot of sparse values \n",
    "    \n",
    "    params:\n",
    "        id_n (Integer) : The number of user's you want in the DF\n",
    "        prd_n (Integer) : The number of products\n",
    "    \n",
    "    returns:\n",
    "        A dataframe with prd_n + 1 columns where majority of the values\n",
    "        are 0\n",
    "    \n",
    "    example:\n",
    "        df = generate_data(\n",
    "            id_n = 10000,\n",
    "            prd_n = 1000\n",
    "        )\n",
    "    '''\n",
    "    \n",
    "    dct = {\n",
    "        'user': [uuid.uuid4() for _ in range(id_n)], \n",
    "        'product': [random.randint(1, prd_n) for _ in range(id_n)],\n",
    "        'value' : [random.randint(1, 100) for N in range(id_n)]\n",
    "    }\n",
    "    d = pd.DataFrame(dct)\n",
    "    \n",
    "    # convert to a pivot table, replace the nan's with 0's\n",
    "    df = d.pivot_table(\n",
    "        values = 'value', index = 'user', columns = 'product'\n",
    "    ).fillna(0)\n",
    "    \n",
    "    categories = ['category1', 'category2', 'category3', 'category4', 'category5']\n",
    "    df['category'] = [random.choice(categories) for _ in range(df.shape[0])]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6042254c-25f5-4cd8-a1b0-38acb9c6ed44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.25 s, sys: 653 ms, total: 1.9 s\n",
      "Wall time: 2.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "df = generate_data(\n",
    "    id_n = 50000,\n",
    "    prd_n = 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6de6a8d-bfb6-4a2c-bdd2-7a0912256bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1001)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c8af3d9-bcc6-4877-bf91-8b1378500632",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_cols = [x for x in df.columns if x != 'category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38718d16-42cb-4e3a-b899-6944f3ebe463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 90.9 ms, sys: 208 ms, total: 299 ms\n",
      "Wall time: 490 ms\n"
     ]
    }
   ],
   "source": [
    "%time vectors = df[ft_cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2cd86a1-8215-4ac4-b9b3-53dce47a65ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 631 ms, sys: 280 ms, total: 911 ms\n",
      "Wall time: 1.06 s\n"
     ]
    }
   ],
   "source": [
    "%time sparse_vectors = scipy.sparse.csr_matrix(df[ft_cols].astype(float).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae5a0bc-8d2e-4427-98ec-43e0363d7590",
   "metadata": {},
   "source": [
    "Now that we have a matrix and a sparse matrix, we can train a model on both to see which one performs better. I'll investigate this on the SVC model from sci-kit learn because support vector machines are known to have a high training and prediction latency based on it's architecture. This was confirmed by sci-kit learn's docs in their implementation here [2]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa19af7-0e45-454f-bf60-616acbf2aae9",
   "metadata": {},
   "source": [
    "## SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c910eab1-5c41-4513-b3a5-5abf1c53803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectors\n",
    "y = df['category'].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(X ,y ,test_size = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cad8466-dd2b-44e5-8cfd-035d2f7eebb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 21s, sys: 4.57 s, total: 3min 26s\n",
      "Wall time: 3min 37s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svc = SVC()\n",
    "svc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2acd23-df08-407a-81c6-3cd7f6373a5e",
   "metadata": {},
   "source": [
    "## SVC - Sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "155a2a2f-131b-4e2d-b3e1-f0c236e2e9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sparse_vectors\n",
    "y = df['category'].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(X ,y ,test_size = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e49a8a94-348c-4175-91d9-f545216eaa7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.26 s, sys: 62.3 ms, total: 5.32 s\n",
      "Wall time: 5.36 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "sparse_svc = SVC()\n",
    "sparse_svc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b2403ac-7960-4f15-8ad2-271988ffd1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.302876480541453"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "185 / 5.91"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64978a6-aebe-40fa-8320-c5c36b0f128b",
   "metadata": {},
   "source": [
    "As we can see from the results above, the training speed of SVC significantly improved when using sparse vectors instead of regular vectors. Based on the time performance, we see that the improvement was 31x, which is quite substantial. This not only reduced run time for training the model but made a substantial improvement on the memory based on the nature and structure of sparse matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2208ea-1b48-4684-a04a-5f368d588ec7",
   "metadata": {},
   "source": [
    "## Predict SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0e14b66-2426-46bb-bd4a-f1b3793b2e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataset to predict on \n",
    "pred_df = generate_data(\n",
    "    id_n = 10000,\n",
    "    prd_n = 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f48fce1c-d861-4a18-8328-ea85afedfe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_pred_mat = scipy.sparse.csr_matrix(pred_df[ft_cols].astype(float).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9b9f033-09f2-4512-9247-049c239bbad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 4s, sys: 460 ms, total: 1min 5s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# regular matrix prediction\n",
    "pred_df['mat_pred'] = pred_df[ft_cols].apply(lambda x : svc.predict(x.values[None])[0], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e883108-e880-4101-9943-d4d80b125d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.4 s, sys: 43.3 ms, total: 14.4 s\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# sparse matrix prediction\n",
    "pred_df['sparse_pred'] = [sparse_svc.predict(row)[0] for row in sparse_pred_mat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd2d93d0-b51c-467a-b10e-66cb44d870fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9393939393939394"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "65/16.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feee56bd-2c20-4a0f-8ba4-684a75896f40",
   "metadata": {},
   "source": [
    "Just as a note, you can send in sparse vectors into prediction even when the model was not trained on sparse data and vice versa. \n",
    "Based on the performance you see above, you can see that the model predicts almost 4x faster when passing in sparse matrices. This is a substantial improvement especially when thinking about the run time and computing costs associated to having a model in production. This will make both real time & batch predictions much easier and efficient to implement in production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce79cffe-35bb-4e97-8f91-094e6aca2fd4",
   "metadata": {},
   "source": [
    "### Concluding Remarks\n",
    "As you might've noticed, this solution most likely won't have a large impact on your application if you are not working with a large & sparse dataset. When the dataset doesn't have a lot of zeros in it, converting it to a sparse matrix and running the calculations won't have the same impact (if any at all). When this is the case, my advice would be to try parallelizing your code to run on multiple pools / threads. This will aid in reducing the amount of time associated to generating predictions & training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e7bcfa-9fca-4c4a-a7bf-76d338098f31",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
