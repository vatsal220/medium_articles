{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98f17e3f-fcce-4aec-93f9-ad76897323cf",
   "metadata": {},
   "source": [
    "# Link Prediction w/ n2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c26a7c0-135c-40c7-84af-16260c96793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install arxiv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77beb5bb-e6db-4d92-88fb-2ee138c24836",
   "metadata": {},
   "source": [
    "You can install the arxiv package in Python with the following command:  \n",
    "`pip install arxiv`  \n",
    "or follow the instructions here : https://pypi.org/project/arxiv/  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53441e5-efb1-4add-9c77-97f08a30f6de",
   "metadata": {},
   "source": [
    "## What is Link Prediction?\n",
    "\n",
    "\n",
    "\n",
    "## Cold Start Problem in Recommendation Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe6b94e0-f903-422f-baab-76010e772026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import arxiv\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from itertools import product\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from node2vec import Node2Vec as n2v\n",
    "from node2vec.edges import HadamardEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5116e841-87c8-4e79-9c1f-6b740c7a9ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "queries = [\n",
    "    'automl', 'machinelearning', 'data', 'phyiscs','mathematics', 'recommendation system', 'nlp', 'neural networks'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b445bcd4-ecdd-4b72-84ff-e36afc5e1a2c",
   "metadata": {},
   "source": [
    "# Fetch Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4e4258-9565-41b0-a01a-4ef1cf783c01",
   "metadata": {},
   "source": [
    "We want to hit th Arxiv API to gather some information about the latest research papers based on the queries we've identified above. This will allow us to then create a network from this research paper data and then we can try to predict links on that network. For the purposes of this article, I will search for a maximum of 1000 results per query, but you don't have to set yourself to the same constraints. The Arxiv API allows users to hit up to 300,000 results per query. The function outlined below will generate a CSV fetching the following information :   \n",
    "```'title', 'date', 'article_id', 'url', 'main_topic', 'all_topics', 'authors', 'year'```   \n",
    "You are able to fetch more information like the `links, summary, article` but I decided not to since those features won't really be used for the purposes of this analysis and tutorial.\n",
    "\n",
    "For reference to the Arxiv API, you can find their detailed documentation here : https://arxiv.org/help/api/user-manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14298db4-2590-4992-a49c-d6c93d962b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_arxiv(queries, max_results = 1000):\n",
    "    '''\n",
    "    This function will search arxiv associated to a set of queries and store\n",
    "    the latest 10000 (max_results) associated to that search.\n",
    "    \n",
    "    params:\n",
    "        queries (List -> Str) : A list of strings containing keywords you want\n",
    "                                to search on Arxiv\n",
    "        max_results (Int) : The maximum number of results you want to see associated\n",
    "                            to your search. Default value is 1000, capped at 300000\n",
    "                            \n",
    "    returns:\n",
    "        This function will return a DataFrame holding the following columns associated\n",
    "        to the queries the user has passed. \n",
    "            `title`, `date`, `article_id`, `url`, `main_topic`, `all_topics`\n",
    "    \n",
    "    example:\n",
    "        research_df = search_arxiv(\n",
    "            queries = ['automl', 'recommender system', 'nlp', 'data science'],\n",
    "            max_results = 10000\n",
    "        )\n",
    "    '''\n",
    "    d = []\n",
    "    searches = []\n",
    "    # hitting the API\n",
    "    for query in queries:\n",
    "        search = arxiv.Search(\n",
    "          query = query,\n",
    "          max_results = max_results,\n",
    "          sort_by = arxiv.SortCriterion.SubmittedDate,\n",
    "          sort_order = arxiv.SortOrder.Descending\n",
    "        )\n",
    "        searches.append(search)\n",
    "    \n",
    "    # Converting search result into df\n",
    "    for search in searches:\n",
    "        for res in search.results():\n",
    "            data = {\n",
    "                'title' : res.title,\n",
    "                'date' : res.published,\n",
    "                'article_id' : res.entry_id,\n",
    "                'url' : res.pdf_url,\n",
    "                'main_topic' : res.primary_category,\n",
    "                'all_topics' : res.categories,\n",
    "                'authors' : res.authors\n",
    "            }\n",
    "            d.append(data)\n",
    "        \n",
    "    d = pd.DataFrame(d)\n",
    "    d['year'] = pd.DatetimeIndex(d['date']).year\n",
    "    \n",
    "    # change article id from url to integer\n",
    "    unique_article_ids = d.article_id.unique()\n",
    "    article_mapping = {art:idx for idx,art in enumerate(unique_article_ids)}\n",
    "    d['article_id'] = d['article_id'].map(article_mapping)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96f77985-1287-4641-bd45-9dbd873c0da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 987 ms, sys: 46.1 ms, total: 1.03 s\n",
      "Wall time: 7.79 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(646, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "research_df = search_arxiv(\n",
    "    queries = queries,\n",
    "    max_results = 100\n",
    ")\n",
    "research_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004e278a-23de-4671-8bd4-853636941495",
   "metadata": {},
   "source": [
    "If you're having trouble querying the data, for reproducibility purposes, the CSV I used for the analysis conducted in this article was uploaded to my GitHub which you can find here. https://github.com/vatsal220/medium_articles/blob/main/link_prediction/data/arxiv_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555b32ed-3c68-412a-bf34-798292d47684",
   "metadata": {},
   "source": [
    "## Generate Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437b2d6f-60f9-4568-afc2-50cb32154cff",
   "metadata": {},
   "source": [
    "Now that we've fetched the data using the Arxiv API, we can generate a network. The network will have the following structure, nodes will be the article_ids and the edges will be all topics connecting a pair of articles. For example, article_id 1 with the following topics `astro-physics, and stats` can be connected to article_id 10 with the topic `stats` and article_id 7 with the topics `astro-physics, math`. This will be a multi-edge network where each edge will hold a weight of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67ef8e9a-0c80-4d4b-a56b-7e50263abacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_network(df, node_col = 'article_id', edge_col = 'main_topic'):\n",
    "    '''\n",
    "    This function will generate a article to article network given an input DataFrame.\n",
    "    It will do so by creating an edge_dictionary where each key is going to be a node\n",
    "    referenced by unique values in node_col and the values will be a list of other nodes\n",
    "    connected to the key through the edge_col.\n",
    "    \n",
    "    params:\n",
    "        df (DataFrame) : The dataset which holds the node and edge columns\n",
    "        node_col (String) : The column name associated to the nodes of the network\n",
    "        edge_col (String) : The column name associated to the edges of the network\n",
    "        \n",
    "    returns:\n",
    "        A networkx graph corresponding to the input dataset\n",
    "        \n",
    "    example:\n",
    "        generate_network(\n",
    "            research_df,\n",
    "            node_col = 'article_id',\n",
    "            edge_col = 'main_topic'\n",
    "        )\n",
    "    '''\n",
    "    edge_dct = {}\n",
    "    for i,g in df.groupby(node_col):\n",
    "        topics = g[edge_col].unique()\n",
    "        edge_df = df[(df[node_col] != i) & (df[edge_col].isin(topics))]\n",
    "        edges = list(edge_df[node_col].unique())\n",
    "        edge_dct[i] = edges\n",
    "    \n",
    "    # create nx network\n",
    "    g = nx.Graph(edge_dct, create_using = nx.MultiGraph)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa528e7e-88df-487a-b364-f9b04573d149",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tp = research_df.explode('all_topics').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b98f8dc1-3bf7-45ce-b2ad-f69c1e08b8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 443 ms, sys: 34.5 ms, total: 477 ms\n",
      "Wall time: 490 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tp_nx = generate_network(\n",
    "    all_tp, \n",
    "    node_col = 'article_id', \n",
    "    edge_col = 'all_topics'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5afa0c52-38c6-4da4-8ac9-358df0aefb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 570\n",
      "Number of edges: 26178\n",
      "Average degree:  91.8526\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(tp_nx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b646d2a-1d5e-4837-870b-7d99153d2728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 351 ms, sys: 3.65 ms, total: 354 ms\n",
      "Wall time: 353 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "research_nx = generate_network(\n",
    "    research_df, \n",
    "    node_col = 'article_id', \n",
    "    edge_col = 'main_topic'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e45a5537-68da-4a97-ae74-b0ccdbcc84be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 570\n",
      "Number of edges: 10698\n",
      "Average degree:  37.5368\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(research_nx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66415397-621f-4ae9-9e2c-388359e33478",
   "metadata": {},
   "source": [
    "## Node2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97bc9ab-f39b-4ef8-833c-6cbe7e1e65ef",
   "metadata": {},
   "source": [
    "This component will cover running node2vec on the graph generated above and creating the associated node embeddings for that network. These embeddings will play a crucial role coming up as they're the main features necessary for building a link prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "066bf93a-ad52-491b-adb1-79fe6481ab9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca960e365f064ff394460ae25c95a8d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [00:10<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.7 s, sys: 143 ms, total: 13.9 s\n",
      "Wall time: 13.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%time g_emb = n2v(research_nx, dimensions=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afca8a21-5aa8-493a-ba57-e83695637ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW = 1 # Node2Vec fit window\n",
    "MIN_COUNT = 1 # Node2Vec min. count\n",
    "BATCH_WORDS = 4 # Node2Vec batch words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5ce72cd-db36-430f-b65e-f7b9b9604120",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = g_emb.fit(\n",
    "    window=WINDOW,\n",
    "    min_count=MIN_COUNT,\n",
    "    batch_words=BATCH_WORDS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eda734d7-6b08-4a76-aca9-6a54948c1e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('300', 0.6815548539161682)\n",
      "('395', 0.6645826697349548)\n",
      "('109', 0.6567216515541077)\n",
      "('363', 0.6363925337791443)\n",
      "('204', 0.6336174607276917)\n",
      "('371', 0.6288920640945435)\n",
      "('139', 0.6258803009986877)\n",
      "('458', 0.6248643398284912)\n",
      "('566', 0.6243730187416077)\n",
      "('274', 0.6211979389190674)\n"
     ]
    }
   ],
   "source": [
    "input_node = '1'\n",
    "for s in mdl.wv.most_similar(input_node, topn = 10):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997a904f-fc1c-4a60-972c-94f39143f64d",
   "metadata": {},
   "source": [
    "## Generate Embeddings DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08f66aff-fe52-4ba1-85e4-32d9ec1cb5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_df = (\n",
    "    pd.DataFrame(\n",
    "        [mdl.wv.get_vector(str(n)) for n in research_nx.nodes()],\n",
    "        index = research_nx.nodes\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca946a47-125a-41a5-9a36-bfd1543d6ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.511957</td>\n",
       "      <td>-0.580585</td>\n",
       "      <td>-0.626385</td>\n",
       "      <td>-0.827639</td>\n",
       "      <td>0.904748</td>\n",
       "      <td>0.777848</td>\n",
       "      <td>0.182476</td>\n",
       "      <td>-1.217629</td>\n",
       "      <td>-0.396125</td>\n",
       "      <td>-1.085773</td>\n",
       "      <td>-0.119347</td>\n",
       "      <td>0.081139</td>\n",
       "      <td>-0.253311</td>\n",
       "      <td>0.879596</td>\n",
       "      <td>0.556270</td>\n",
       "      <td>0.284939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.549100</td>\n",
       "      <td>0.134050</td>\n",
       "      <td>-1.983533</td>\n",
       "      <td>-1.282142</td>\n",
       "      <td>0.762598</td>\n",
       "      <td>0.978624</td>\n",
       "      <td>0.186682</td>\n",
       "      <td>0.436884</td>\n",
       "      <td>-1.926421</td>\n",
       "      <td>-1.661931</td>\n",
       "      <td>-0.821661</td>\n",
       "      <td>-2.232859</td>\n",
       "      <td>-1.446645</td>\n",
       "      <td>-0.479345</td>\n",
       "      <td>1.687179</td>\n",
       "      <td>-1.335484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.488350</td>\n",
       "      <td>-0.587227</td>\n",
       "      <td>-0.625464</td>\n",
       "      <td>-0.782213</td>\n",
       "      <td>0.869252</td>\n",
       "      <td>0.836026</td>\n",
       "      <td>0.185684</td>\n",
       "      <td>-1.158214</td>\n",
       "      <td>-0.469872</td>\n",
       "      <td>-1.117828</td>\n",
       "      <td>-0.063733</td>\n",
       "      <td>0.220845</td>\n",
       "      <td>-0.207277</td>\n",
       "      <td>0.864076</td>\n",
       "      <td>0.567868</td>\n",
       "      <td>0.222027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.520829</td>\n",
       "      <td>-0.603254</td>\n",
       "      <td>-0.620381</td>\n",
       "      <td>-0.765303</td>\n",
       "      <td>0.907810</td>\n",
       "      <td>0.850281</td>\n",
       "      <td>0.182577</td>\n",
       "      <td>-1.161945</td>\n",
       "      <td>-0.394557</td>\n",
       "      <td>-1.037542</td>\n",
       "      <td>-0.090025</td>\n",
       "      <td>0.194334</td>\n",
       "      <td>-0.269508</td>\n",
       "      <td>0.866738</td>\n",
       "      <td>0.623747</td>\n",
       "      <td>0.283081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.536191</td>\n",
       "      <td>-0.615628</td>\n",
       "      <td>-0.488054</td>\n",
       "      <td>-0.758666</td>\n",
       "      <td>0.870371</td>\n",
       "      <td>0.816817</td>\n",
       "      <td>0.229364</td>\n",
       "      <td>-1.192694</td>\n",
       "      <td>-0.459576</td>\n",
       "      <td>-1.160274</td>\n",
       "      <td>-0.103331</td>\n",
       "      <td>0.272849</td>\n",
       "      <td>-0.131484</td>\n",
       "      <td>0.901864</td>\n",
       "      <td>0.598280</td>\n",
       "      <td>0.257405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.511957 -0.580585 -0.626385 -0.827639  0.904748  0.777848  0.182476   \n",
       "1 -1.549100  0.134050 -1.983533 -1.282142  0.762598  0.978624  0.186682   \n",
       "2 -0.488350 -0.587227 -0.625464 -0.782213  0.869252  0.836026  0.185684   \n",
       "3 -0.520829 -0.603254 -0.620381 -0.765303  0.907810  0.850281  0.182577   \n",
       "4 -0.536191 -0.615628 -0.488054 -0.758666  0.870371  0.816817  0.229364   \n",
       "\n",
       "         7         8         9         10        11        12        13  \\\n",
       "0 -1.217629 -0.396125 -1.085773 -0.119347  0.081139 -0.253311  0.879596   \n",
       "1  0.436884 -1.926421 -1.661931 -0.821661 -2.232859 -1.446645 -0.479345   \n",
       "2 -1.158214 -0.469872 -1.117828 -0.063733  0.220845 -0.207277  0.864076   \n",
       "3 -1.161945 -0.394557 -1.037542 -0.090025  0.194334 -0.269508  0.866738   \n",
       "4 -1.192694 -0.459576 -1.160274 -0.103331  0.272849 -0.131484  0.901864   \n",
       "\n",
       "         14        15  \n",
       "0  0.556270  0.284939  \n",
       "1  1.687179 -1.335484  \n",
       "2  0.567868  0.222027  \n",
       "3  0.623747  0.283081  \n",
       "4  0.598280  0.257405  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cd6bb7-c281-47a8-a62c-3970845ef989",
   "metadata": {},
   "source": [
    "## Recommendations w/ Distance Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0017cc-caf6-40b2-ad3c-3aaca18d4994",
   "metadata": {},
   "source": [
    "Now that we have a embedding vector representing each node in the network, we can then use distance measures like cosine similarity, euclidean distance, manhattan distance, etc. to measure the amount of distance between nodes. The assumption that we're making by using these distance measures is that nodes in close proximity with each other should also have an edge connecting each other. This is a good assumption to make as node2vec tries to preserve the initial structure of the original input graph. Now we can essentially write out code to measure similarity levels between two vectors using cosine similarity (or a different distance measure) and identify pairs of nodes which don't currently have an edge between them but do have a large similarity should create an edge between them. This interpretation can be different for multi / weighted / directed graphs. Pick and use a similarity measure appropriate to the network and problem you're trying to solve. Also be aware that different measures have different interperations, for this problem you want to pick maximal cosine similarity scores whereas if you were to use something like euclidean distance, you would want to pick the minimal distance between two vectors.\n",
    "\n",
    "On a side note, I do want to mention that the curse of dimensionality is rampant when solving these types of problems. It's especially problematic when using euclidean distance in particular to measure the distance between vectors in higher dimensions. The term higher dimensions is broad and open to interpretation, the threshold for a dimension to be \"high\" is not strictly defined and varies from problem to problem. Without going to deep into the mathematics behind things, euclidean distance is not a good measure to use for sparse or high dimensional vectors. You can reference this post on stack exchange which outlines the mathematical reasoning as to why this is the case. \n",
    "\n",
    "- https://stats.stackexchange.com/questions/29627/euclidean-distance-is-usually-not-good-for-sparse-data-and-more-general-case\n",
    "- https://stats.stackexchange.com/questions/99171/why-is-euclidean-distance-not-a-good-metric-in-high-dimensions\n",
    "\n",
    "For more on the curse of dimensionality, refer to this [paper](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf) by the Computer Science department from the University of Washington."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edf712d2-f670-4d47-b60a-3854fe138bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_links(G, df, article_id, N):\n",
    "    '''\n",
    "    This function will predict the top N links a node (article_id) should be connected with\n",
    "    which it is not already connected with in G.\n",
    "    \n",
    "    params:\n",
    "        G (Netowrkx Graph) : The network used to create the embeddings\n",
    "        df (DataFrame) : The dataframe which has embeddings associated to each node\n",
    "        article_id (Integer) : The article you're interested \n",
    "        N (Integer) : The number of recommended links you want to return\n",
    "        \n",
    "    returns:\n",
    "        This function will return a list of nodes the input node should be connected with.\n",
    "    '''\n",
    "    \n",
    "    # separate target article with all others\n",
    "    article = df[df.index == article_id]\n",
    "    \n",
    "    # other articles are all articles which the current doesn't have an edge connecting\n",
    "    all_nodes = G.nodes()\n",
    "    other_nodes = [n for n in all_nodes if n not in list(G.adj[article_id]) + [article_id]]\n",
    "    other_articles = df[df.index.isin(other_nodes)]\n",
    "    \n",
    "    # get similarity of current reader and all other readers\n",
    "    sim = cosine_similarity(article, other_articles)[0].tolist()\n",
    "    idx = other_articles.index.tolist()\n",
    "    \n",
    "    # create a similarity dictionary for this user w.r.t all other users\n",
    "    idx_sim = dict(zip(idx, sim))\n",
    "    idx_sim = sorted(idx_sim.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    similar_articles = idx_sim[:N]\n",
    "    articles = [art[0] for art in similar_articles]\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d620ab80-41f1-438c-9f10-f9a5bdcaf590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[300, 395, 109, 363, 204, 371, 139, 458, 566, 274]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_links(G = research_nx, df = emb_df, article_id = 1, N = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab008511-b524-4207-9177-f4cca968fdc6",
   "metadata": {},
   "source": [
    "## Modelling Based Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61708a7e-18c4-4cb3-b6e8-74bc2446b13d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8eb0724-c0fa-4124-966e-587ef2a0e93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_nodes = list(research_nx.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9994925c-c38d-4681-af7d-880398bdb0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.4 ms, sys: 11.8 ms, total: 54.3 ms\n",
      "Wall time: 57.6 ms\n"
     ]
    }
   ],
   "source": [
    "%time all_possible_edges = [(x,y) for (x,y) in product(unique_nodes, unique_nodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eca2b97c-1bf9-4b56-84ee-8cef35670442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162165"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_possible_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e275d29-759e-44d6-bdd2-7c18435f893e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324900"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_possible_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "24f60661-7621-45b4-972c-8f571744a9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 734 ms, sys: 32.4 ms, total: 766 ms\n",
      "Wall time: 780 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "edge_features = [\n",
    "    (mdl.wv.get_vector(str(i))+mdl.wv.get_vector(str(j))) for i,j in all_possible_edges\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "323cde89-2c53-4ccb-8365-064624819fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = list(research_nx.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2bdf3789-8348-4c8b-86e9-5e8fa8f09797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 4s, sys: 227 ms, total: 1min 4s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%time is_con = [1 if e in edges else 0 for e in all_possible_edges]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5fa3a543-06db-4a37-886e-f1e3cb6faf64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10698"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(is_con)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fe205e-cc61-4f91-acce-449792808bb0",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d16a8551-a343-4807-bab1-393e1293fbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(edge_features)\n",
    "y = is_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "874593a1-0f94-44b4-b758-485171ed0af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2309d219-ecc9-46b0-9fcb-03d9a7afb64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 57s, sys: 351 ms, total: 1min 57s\n",
      "Wall time: 1min 57s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# classifier\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "# train the model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880d1153-1e48-499e-9dc0-122c3425a705",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b0022514-47e6-4f97-919d-c951fde21abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "y_true = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "af2e8de6-4636-4443-95e8-d7e4c0c1691c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.059086223731077636"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matthews_corrcoef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "29e392c3-ef29-4606-a5db-da60a3331dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy :  0.9658356417359187\n",
      "Training Accuracy :  0.9673704729660408\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "x_pred = clf.predict(X_train)\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "train_acc = accuracy_score(y_train, x_pred)\n",
    "print(\"Testing Accuracy : \", test_acc)\n",
    "print(\"Training Accuracy : \", train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "67a09428-6855-4737-8041-4caead755055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[78408,  2667],\n",
       "       [  108,    42]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463d29d4-49ad-43c9-b394-cc3088009dbe",
   "metadata": {},
   "source": [
    "## Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b3d929e1-d590-4ed7-b835-b21e60d9008c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ft = [(mdl.wv.get_vector(str('42'))+mdl.wv.get_vector(str('210')))]\n",
    "clf.predict(pred_ft)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b67e10-927d-4fc7-bc3b-0ef3115f7c19",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b89e85f-bee0-41fc-97f4-5aa565d84479",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.convert_matrix.from_numpy_array(arr, create_using = nx.DiGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "856c484a-2cd4-4628-a724-511b2b197771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 2\n",
      "Number of edges: 4\n",
      "Average in degree:   2.0000\n",
      "Average out degree:   2.0000\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c5c51e77-9461-4810-959c-70601813d687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nx.draw(g, with_labels = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "78010569-6bb7-4122-8d19-0a6764513bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat1 = np.array([[0,2,3,0], [2,0,1,1], [3,1,0,0], [0,1,0,0]])\n",
    "mat2 = np.array([[0,4,5,3], [4,0,1,2], [5,1,0,0], [3,2,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "22e22ca1-cf2b-4e2c-969f-e41b3af14c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23,  3,  2,  4],\n",
       "       [ 8, 11, 10,  6],\n",
       "       [ 4, 12, 16, 11],\n",
       "       [ 4,  0,  1,  2]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1@mat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8f5caedb-ee93-4ed3-a2ec-62238443cc06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23,  3,  2,  4],\n",
       "       [ 8, 11, 10,  6],\n",
       "       [ 4, 12, 16, 11],\n",
       "       [ 4,  0,  1,  2]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1.dot(mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "af53ccb0-9ab3-4e72-9faf-0654e324a227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  8, 15,  0],\n",
       "       [ 8,  0,  1,  2],\n",
       "       [15,  1,  0,  0],\n",
       "       [ 0,  2,  0,  0]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1*mat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f7cabe8-1e62-40df-b705-9fe404ca397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat1 = np.array([[0,2], [2,0]])\n",
    "mat2 = np.array([[0,4], [4,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3ecaf7a5-62b3-4fa4-811f-2fa154a5af02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8, 0],\n",
       "       [0, 8]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1@mat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b943190d-b470-46bd-b248-50addf4d0033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 8],\n",
       "       [8, 0]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1*mat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417dd5a3-c63f-47c8-865e-7de2264c0082",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d250cc32-6b61-442b-9b7d-bf24c5c2b9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 2, 4],\n",
       "       [1, 3, 6],\n",
       "       [4, 8, 6]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_org = np.array(\n",
    "    [\n",
    "        [1,4,5,6,8,7,6,5,4,2,3,5],\n",
    "        [2,3,4,6,2,1,4,4,6,3,2,1],\n",
    "        [0,1,2,5,3,5,6,4,3,2,6,2],\n",
    "        [0,7,5,7,2,3,4,5,6,4,2,1],\n",
    "        [0,1,2,5,3,5,6,4,3,2,6,2],\n",
    "        [0,1,2,5,3,5,6,4,3,2,6,2],\n",
    "        [1,4,5,6,8,7,6,5,4,2,3,5],\n",
    "        [0,1,2,5,3,5,6,4,3,2,6,2]\n",
    "    ]\n",
    ")\n",
    "\n",
    "def create_subarray(arr, r_idx, c_idx):\n",
    "    try:\n",
    "        return arr[np.ix_(r_idx, c_idx)]\n",
    "    except:\n",
    "        raise IndexError(\"Index is out of bounds\")\n",
    "\n",
    "s1 = [1,4,6]\n",
    "create_subarray(m_org, s1, s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8d423304-a69b-4e24-8a5e-dac95e5d7337",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = [1,4,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fbab4afd-9da6-4bd7-bb1c-c3ad580ef5cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 2, 4],\n",
       "       [1, 3, 6],\n",
       "       [4, 8, 6]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_org[np.asarray(s1)[:, None], s1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc64011-848e-4263-b524-6775477d46f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38f6d79-92da-481a-a7e5-22e307f6fbca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
