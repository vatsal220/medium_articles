{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98f17e3f-fcce-4aec-93f9-ad76897323cf",
   "metadata": {},
   "source": [
    "# Link Prediction w/ n2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c26a7c0-135c-40c7-84af-16260c96793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe6b94e0-f903-422f-baab-76010e772026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import arxiv\n",
    "\n",
    "from node2vec import node2vec as n2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5116e841-87c8-4e79-9c1f-6b740c7a9ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "queries = [\n",
    "    'automl', 'machinelearning', 'data', 'phyiscs','mathematics', 'recommendation system', 'nlp', 'neural networks'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b445bcd4-ecdd-4b72-84ff-e36afc5e1a2c",
   "metadata": {},
   "source": [
    "# Fetch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14298db4-2590-4992-a49c-d6c93d962b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_arxiv(queries, max_results = 1000):\n",
    "    '''\n",
    "    This function will search arxiv associated to a set of queries and store\n",
    "    the latest 10000 (max_results) associated to that search.\n",
    "    \n",
    "    params:\n",
    "        queries (List -> Str) : A list of strings containing keywords you want\n",
    "                                to search on Arxiv\n",
    "        max_results (Int) : The maximum number of results you want to see associated\n",
    "                            to your search. Default value is 1000, capped at 300000\n",
    "                            \n",
    "    returns:\n",
    "        This function will return a DataFrame holding the following columns associated\n",
    "        to the queries the user has passed. \n",
    "            `title`, `date`, `article_id`, `url`, `main_topic`, `all_topics`\n",
    "    \n",
    "    example:\n",
    "        research_df = search_arxiv(\n",
    "            queries = ['automl', 'recommender system', 'nlp', 'data science'],\n",
    "            max_results = 10000\n",
    "        )\n",
    "    '''\n",
    "    d = []\n",
    "    searches = []\n",
    "    # hitting the API\n",
    "    for query in queries:\n",
    "        search = arxiv.Search(\n",
    "          query = query,\n",
    "          max_results = max_results,\n",
    "          sort_by = arxiv.SortCriterion.SubmittedDate,\n",
    "          sort_order = arxiv.SortOrder.Descending\n",
    "        )\n",
    "        searches.append(search)\n",
    "    \n",
    "    # Converting search result into df\n",
    "    for search in searches:\n",
    "        for res in search.results():\n",
    "            data = {\n",
    "                'title' : res.title,\n",
    "                'date' : res.published,\n",
    "                'article_id' : res.entry_id,\n",
    "                'url' : res.pdf_url,\n",
    "                'main_topic' : res.primary_category,\n",
    "                'all_topics' : res.categories,\n",
    "                'authors' : res.authors\n",
    "            }\n",
    "            d.append(data)\n",
    "        \n",
    "    d = pd.DataFrame(d)\n",
    "    d['year'] = pd.DatetimeIndex(d['date']).year\n",
    "    \n",
    "    # change article id from url to integer\n",
    "    unique_article_ids = d.article_id.unique()\n",
    "    article_mapping = {art:idx for idx,art in enumerate(unique_article_ids)}\n",
    "    d['article_id'] = d['article_id'].map(article_mapping)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96f77985-1287-4641-bd45-9dbd873c0da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.02 s, sys: 456 ms, total: 8.48 s\n",
      "Wall time: 3min 39s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5332, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "research_df = search_arxiv(\n",
    "    queries = queries,\n",
    "    max_results = 1000\n",
    ")\n",
    "research_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555b32ed-3c68-412a-bf34-798292d47684",
   "metadata": {},
   "source": [
    "## Generate Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9d6b08-ef13-4ac1-bc69-61529d33679e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16641c8-527f-4836-91eb-64fd20312914",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
