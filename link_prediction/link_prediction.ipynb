{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98f17e3f-fcce-4aec-93f9-ad76897323cf",
   "metadata": {},
   "source": [
    "# Link Prediction w/ n2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c26a7c0-135c-40c7-84af-16260c96793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install arxiv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77beb5bb-e6db-4d92-88fb-2ee138c24836",
   "metadata": {},
   "source": [
    "You can install the arxiv package in Python with the following command:  \n",
    "`pip install arxiv`  \n",
    "or follow the instructions here : https://pypi.org/project/arxiv/  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe6b94e0-f903-422f-baab-76010e772026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import arxiv\n",
    "\n",
    "from node2vec import Node2Vec as n2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5116e841-87c8-4e79-9c1f-6b740c7a9ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "queries = [\n",
    "    'automl', 'machinelearning', 'data', 'phyiscs','mathematics', 'recommendation system', 'nlp', 'neural networks'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b445bcd4-ecdd-4b72-84ff-e36afc5e1a2c",
   "metadata": {},
   "source": [
    "# Fetch Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4e4258-9565-41b0-a01a-4ef1cf783c01",
   "metadata": {},
   "source": [
    "We want to hit th Arxiv API to gather some information about the latest research papers based on the queries we've identified above. This will allow us to then create a network from this research paper data and then we can try to predict links on that network. For the purposes of this article, I will search for a maximum of 1000 results per query, but you don't have to set yourself to the same constraints. The Arxiv API allows users to hit up to 300,000 results per query. The function outlined below will generate a CSV fetching the following information :   \n",
    "```'title', 'date', 'article_id', 'url', 'main_topic', 'all_topics', 'authors', 'year'```   \n",
    "You are able to fetch more information like the `links, summary, article` but I decided not to since those features won't really be used for the purposes of this analysis and tutorial.\n",
    "\n",
    "For reference to the Arxiv API, you can find their detailed documentation here : https://arxiv.org/help/api/user-manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14298db4-2590-4992-a49c-d6c93d962b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_arxiv(queries, max_results = 1000):\n",
    "    '''\n",
    "    This function will search arxiv associated to a set of queries and store\n",
    "    the latest 10000 (max_results) associated to that search.\n",
    "    \n",
    "    params:\n",
    "        queries (List -> Str) : A list of strings containing keywords you want\n",
    "                                to search on Arxiv\n",
    "        max_results (Int) : The maximum number of results you want to see associated\n",
    "                            to your search. Default value is 1000, capped at 300000\n",
    "                            \n",
    "    returns:\n",
    "        This function will return a DataFrame holding the following columns associated\n",
    "        to the queries the user has passed. \n",
    "            `title`, `date`, `article_id`, `url`, `main_topic`, `all_topics`\n",
    "    \n",
    "    example:\n",
    "        research_df = search_arxiv(\n",
    "            queries = ['automl', 'recommender system', 'nlp', 'data science'],\n",
    "            max_results = 10000\n",
    "        )\n",
    "    '''\n",
    "    d = []\n",
    "    searches = []\n",
    "    # hitting the API\n",
    "    for query in queries:\n",
    "        search = arxiv.Search(\n",
    "          query = query,\n",
    "          max_results = max_results,\n",
    "          sort_by = arxiv.SortCriterion.SubmittedDate,\n",
    "          sort_order = arxiv.SortOrder.Descending\n",
    "        )\n",
    "        searches.append(search)\n",
    "    \n",
    "    # Converting search result into df\n",
    "    for search in searches:\n",
    "        for res in search.results():\n",
    "            data = {\n",
    "                'title' : res.title,\n",
    "                'date' : res.published,\n",
    "                'article_id' : res.entry_id,\n",
    "                'url' : res.pdf_url,\n",
    "                'main_topic' : res.primary_category,\n",
    "                'all_topics' : res.categories,\n",
    "                'authors' : res.authors\n",
    "            }\n",
    "            d.append(data)\n",
    "        \n",
    "    d = pd.DataFrame(d)\n",
    "    d['year'] = pd.DatetimeIndex(d['date']).year\n",
    "    \n",
    "    # change article id from url to integer\n",
    "    unique_article_ids = d.article_id.unique()\n",
    "    article_mapping = {art:idx for idx,art in enumerate(unique_article_ids)}\n",
    "    d['article_id'] = d['article_id'].map(article_mapping)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96f77985-1287-4641-bd45-9dbd873c0da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.04 s, sys: 63 ms, total: 1.11 s\n",
      "Wall time: 11.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(646, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "research_df = search_arxiv(\n",
    "    queries = queries,\n",
    "    max_results = 100\n",
    ")\n",
    "research_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004e278a-23de-4671-8bd4-853636941495",
   "metadata": {},
   "source": [
    "If you're having trouble querying the data, for reproducibility purposes, the CSV I used for the analysis conducted in this article was uploaded to my GitHub which you can find here. https://github.com/vatsal220/medium_articles/blob/main/link_prediction/data/arxiv_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555b32ed-3c68-412a-bf34-798292d47684",
   "metadata": {},
   "source": [
    "## Generate Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437b2d6f-60f9-4568-afc2-50cb32154cff",
   "metadata": {},
   "source": [
    "Now that we've fetched the data using the Arxiv API, we can generate a network. The network will have the following structure, nodes will be the article_ids and the edges will be all topics connecting a pair of articles. For example, article_id 1 with the following topics `astro-physics, and stats` can be connected to article_id 10 with the topic `stats` and article_id 7 with the topics `astro-physics, math`. This will be a multi-edge network where each edge will hold a weight of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec9d6b08-ef13-4ac1-bc69-61529d33679e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_df = research_df.explode('all_topics').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cab8e97-3700-4d7d-b1ef-13a94584d92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_network(df, node_col = 'article_id', edge_col = 'main_topic'):\n",
    "    '''\n",
    "    This function will generate a article to article network given an input DataFrame.\n",
    "    It will do so by creating an edge_dictionary where each key is going to be a node\n",
    "    referenced by unique values in node_col and the values will be a list of other nodes\n",
    "    connected to the key through the edge_col.\n",
    "    \n",
    "    params:\n",
    "        df (DataFrame) : The dataset which holds the node and edge columns\n",
    "        node_col (String) : The column name associated to the nodes of the network\n",
    "        edge_col (String) : The column name associated to the edges of the network\n",
    "        \n",
    "    returns:\n",
    "        A networkx graph corresponding to the input dataset\n",
    "        \n",
    "    example:\n",
    "        generate_network(\n",
    "            research_df,\n",
    "            node_col = 'article_id',\n",
    "            edge_col = 'main_topic'\n",
    "        )\n",
    "    '''\n",
    "    edge_dct = {}\n",
    "    for i,g in df.groupby(node_col):\n",
    "        topics = df[edge_col].unique()\n",
    "        edge_df = df[(df[node_col] != i) & (df[edge_col].isin(topics))]\n",
    "        edges = list(edge_df[node_col].unique())\n",
    "        edge_dct[i] = edges\n",
    "    \n",
    "    # create nx network\n",
    "    g = nx.Graph(edge_dct)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6878f12-a0bc-4070-8fca-689b01154970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 724 ms, sys: 45.2 ms, total: 769 ms\n",
      "Wall time: 789 ms\n"
     ]
    }
   ],
   "source": [
    "%time research_network = generate_network(research_df, node_col = 'article_id', edge_col = 'main_topic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f8ca352-20f3-4358-95c7-2bcf444d09eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 562\n",
      "Number of edges: 157641\n",
      "Average degree: 561.0000\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(research_network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56b5eb69-e758-4dc6-a503-1cde7883d696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 729 ms, sys: 19.1 ms, total: 748 ms\n",
      "Wall time: 748 ms\n"
     ]
    }
   ],
   "source": [
    "%time all_topic_nx = generate_network(r_df, node_col = 'article_id', edge_col = 'all_topics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00cb2bd2-50a5-480c-9e1d-194163497ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 562\n",
      "Number of edges: 157641\n",
      "Average degree: 561.0000\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(all_topic_nx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66415397-621f-4ae9-9e2c-388359e33478",
   "metadata": {},
   "source": [
    "## Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "066bf93a-ad52-491b-adb1-79fe6481ab9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a456c24533d49cfa98ca2aab2c1a63c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/562 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [00:25<00:00,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 57s, sys: 4.73 s, total: 6min 2s\n",
      "Wall time: 6min 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%time g_emb = n2v(research_network, dimensions=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afca8a21-5aa8-493a-ba57-e83695637ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW = 1 # Node2Vec fit window\n",
    "MIN_COUNT = 1 # Node2Vec min. count\n",
    "BATCH_WORDS = 4 # Node2Vec batch words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5ce72cd-db36-430f-b65e-f7b9b9604120",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = g_emb.fit(\n",
    "    window=WINDOW,\n",
    "    min_count=MIN_COUNT,\n",
    "    batch_words=BATCH_WORDS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eda734d7-6b08-4a76-aca9-6a54948c1e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('211', 0.9128776788711548)\n",
      "('521', 0.911181628704071)\n",
      "('40', 0.9052026271820068)\n",
      "('124', 0.9023550152778625)\n",
      "('287', 0.9022865891456604)\n",
      "('132', 0.8979486227035522)\n",
      "('138', 0.8978955745697021)\n",
      "('467', 0.8966530561447144)\n",
      "('170', 0.8965973854064941)\n",
      "('531', 0.8943594098091125)\n"
     ]
    }
   ],
   "source": [
    "input_node = '1'\n",
    "for s in mdl.wv.most_similar(input_node, topn = 10):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46a42a8f-0018-48ac-b836-e6c79d356303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>article_id</th>\n",
       "      <th>url</th>\n",
       "      <th>main_topic</th>\n",
       "      <th>all_topics</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hubble Asteroid Hunter: I. Identifying asteroi...</td>\n",
       "      <td>2022-02-01 06:56:20+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>http://arxiv.org/pdf/2202.00246v1</td>\n",
       "      <td>astro-ph.EP</td>\n",
       "      <td>astro-ph.EP</td>\n",
       "      <td>[Sandor Kruk, Pablo García Martín, Marcel Pope...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hubble Asteroid Hunter: I. Identifying asteroi...</td>\n",
       "      <td>2022-02-01 06:56:20+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>http://arxiv.org/pdf/2202.00246v1</td>\n",
       "      <td>astro-ph.EP</td>\n",
       "      <td>astro-ph.IM</td>\n",
       "      <td>[Sandor Kruk, Pablo García Martín, Marcel Pope...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "1  Hubble Asteroid Hunter: I. Identifying asteroi...   \n",
       "1  Hubble Asteroid Hunter: I. Identifying asteroi...   \n",
       "\n",
       "                       date  article_id                                url  \\\n",
       "1 2022-02-01 06:56:20+00:00           1  http://arxiv.org/pdf/2202.00246v1   \n",
       "1 2022-02-01 06:56:20+00:00           1  http://arxiv.org/pdf/2202.00246v1   \n",
       "\n",
       "    main_topic   all_topics  \\\n",
       "1  astro-ph.EP  astro-ph.EP   \n",
       "1  astro-ph.EP  astro-ph.IM   \n",
       "\n",
       "                                             authors  year  \n",
       "1  [Sandor Kruk, Pablo García Martín, Marcel Pope...  2022  \n",
       "1  [Sandor Kruk, Pablo García Martín, Marcel Pope...  2022  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_df[r_df.article_id == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fdbe180-b1d1-43a9-b9c6-4cfbd3b664e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>article_id</th>\n",
       "      <th>url</th>\n",
       "      <th>main_topic</th>\n",
       "      <th>all_topics</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>Topological Defects Induced High-Spin Quartet ...</td>\n",
       "      <td>2022-02-08 13:34:05+00:00</td>\n",
       "      <td>521</td>\n",
       "      <td>http://arxiv.org/pdf/2202.03853v1</td>\n",
       "      <td>cond-mat.mes-hall</td>\n",
       "      <td>cond-mat.mes-hall</td>\n",
       "      <td>[Can Li, Yu Liu, Yufeng Liu, Fu-Hua Xue, Danda...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "577  Topological Defects Induced High-Spin Quartet ...   \n",
       "\n",
       "                         date  article_id                                url  \\\n",
       "577 2022-02-08 13:34:05+00:00         521  http://arxiv.org/pdf/2202.03853v1   \n",
       "\n",
       "            main_topic         all_topics  \\\n",
       "577  cond-mat.mes-hall  cond-mat.mes-hall   \n",
       "\n",
       "                                               authors  year  \n",
       "577  [Can Li, Yu Liu, Yufeng Liu, Fu-Hua Xue, Danda...  2022  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_df[r_df.article_id == 521]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997a904f-fc1c-4a60-972c-94f39143f64d",
   "metadata": {},
   "source": [
    "## Generate Embeddings DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08f66aff-fe52-4ba1-85e4-32d9ec1cb5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_df = (\n",
    "    pd.DataFrame(\n",
    "        [mdl.wv.get_vector(str(n)) for n in research_network.nodes()],\n",
    "        index = research_network.nodes\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca946a47-125a-41a5-9a36-bfd1543d6ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.128435</td>\n",
       "      <td>-0.049074</td>\n",
       "      <td>0.132459</td>\n",
       "      <td>-0.102469</td>\n",
       "      <td>0.844356</td>\n",
       "      <td>0.267155</td>\n",
       "      <td>0.225001</td>\n",
       "      <td>-0.419419</td>\n",
       "      <td>-0.135403</td>\n",
       "      <td>-0.002126</td>\n",
       "      <td>-0.086459</td>\n",
       "      <td>-0.163671</td>\n",
       "      <td>-0.006720</td>\n",
       "      <td>0.043489</td>\n",
       "      <td>0.237503</td>\n",
       "      <td>0.019430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.096374</td>\n",
       "      <td>0.018799</td>\n",
       "      <td>0.035309</td>\n",
       "      <td>-0.023356</td>\n",
       "      <td>0.524462</td>\n",
       "      <td>0.257324</td>\n",
       "      <td>0.579559</td>\n",
       "      <td>-0.595028</td>\n",
       "      <td>-0.237835</td>\n",
       "      <td>-0.113283</td>\n",
       "      <td>0.068707</td>\n",
       "      <td>-0.420708</td>\n",
       "      <td>0.095696</td>\n",
       "      <td>-0.093512</td>\n",
       "      <td>0.159015</td>\n",
       "      <td>0.001616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.039072</td>\n",
       "      <td>-0.151964</td>\n",
       "      <td>0.139572</td>\n",
       "      <td>-0.417229</td>\n",
       "      <td>0.720359</td>\n",
       "      <td>0.410377</td>\n",
       "      <td>0.155613</td>\n",
       "      <td>-0.352993</td>\n",
       "      <td>0.041561</td>\n",
       "      <td>-0.395659</td>\n",
       "      <td>0.130601</td>\n",
       "      <td>-0.000469</td>\n",
       "      <td>-0.223700</td>\n",
       "      <td>-0.164071</td>\n",
       "      <td>0.044049</td>\n",
       "      <td>0.179982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.163633</td>\n",
       "      <td>0.070856</td>\n",
       "      <td>-0.186758</td>\n",
       "      <td>-0.188014</td>\n",
       "      <td>0.689734</td>\n",
       "      <td>0.305346</td>\n",
       "      <td>0.171601</td>\n",
       "      <td>-0.403026</td>\n",
       "      <td>-0.155164</td>\n",
       "      <td>-0.409362</td>\n",
       "      <td>0.080607</td>\n",
       "      <td>-0.192482</td>\n",
       "      <td>0.092849</td>\n",
       "      <td>0.082888</td>\n",
       "      <td>0.109581</td>\n",
       "      <td>0.110443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.094581</td>\n",
       "      <td>-0.131820</td>\n",
       "      <td>0.265450</td>\n",
       "      <td>-0.071456</td>\n",
       "      <td>0.753454</td>\n",
       "      <td>0.235651</td>\n",
       "      <td>0.430763</td>\n",
       "      <td>-0.240429</td>\n",
       "      <td>-0.041164</td>\n",
       "      <td>-0.160510</td>\n",
       "      <td>-0.171398</td>\n",
       "      <td>-0.306116</td>\n",
       "      <td>0.137343</td>\n",
       "      <td>-0.272153</td>\n",
       "      <td>0.346461</td>\n",
       "      <td>0.089041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.128435 -0.049074  0.132459 -0.102469  0.844356  0.267155  0.225001   \n",
       "1  0.096374  0.018799  0.035309 -0.023356  0.524462  0.257324  0.579559   \n",
       "2 -0.039072 -0.151964  0.139572 -0.417229  0.720359  0.410377  0.155613   \n",
       "3  0.163633  0.070856 -0.186758 -0.188014  0.689734  0.305346  0.171601   \n",
       "4  0.094581 -0.131820  0.265450 -0.071456  0.753454  0.235651  0.430763   \n",
       "\n",
       "         7         8         9         10        11        12        13  \\\n",
       "0 -0.419419 -0.135403 -0.002126 -0.086459 -0.163671 -0.006720  0.043489   \n",
       "1 -0.595028 -0.237835 -0.113283  0.068707 -0.420708  0.095696 -0.093512   \n",
       "2 -0.352993  0.041561 -0.395659  0.130601 -0.000469 -0.223700 -0.164071   \n",
       "3 -0.403026 -0.155164 -0.409362  0.080607 -0.192482  0.092849  0.082888   \n",
       "4 -0.240429 -0.041164 -0.160510 -0.171398 -0.306116  0.137343 -0.272153   \n",
       "\n",
       "         14        15  \n",
       "0  0.237503  0.019430  \n",
       "1  0.159015  0.001616  \n",
       "2  0.044049  0.179982  \n",
       "3  0.109581  0.110443  \n",
       "4  0.346461  0.089041  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fe205e-cc61-4f91-acce-449792808bb0",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16a8551-a343-4807-bab1-393e1293fbd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2309d219-ecc9-46b0-9fcb-03d9a7afb64d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "880d1153-1e48-499e-9dc0-122c3425a705",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a09428-6855-4737-8041-4caead755055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae8e831-6341-49d6-883a-7b4761f2a789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "463d29d4-49ad-43c9-b394-cc3088009dbe",
   "metadata": {},
   "source": [
    "## Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d929e1-d590-4ed7-b835-b21e60d9008c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73e4de5-9e5e-4ef8-8cb8-0adb6fd95cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67b67e10-927d-4fc7-bc3b-0ef3115f7c19",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
