{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e408515d-719e-4050-a36a-c0c8dbccefb2",
   "metadata": {},
   "source": [
    "# Parallelize Sci-Kit Learn Models & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be1c3d71-81f5-4974-9488-2bebe76df1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from random import randint\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing import cpu_count\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbf29c3-8ff8-4142-a718-d168acd0570f",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd03b027-ec54-455c-ba12-e7fcb3b9389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_books = 3000, n_genres = 10, n_authors = 450, n_publishers = 50, n_readers = 30000, dataset_size = 100000):\n",
    "    '''\n",
    "    This function will generate a dataset with features associated to\n",
    "    book data set. The dataset will have the following columns : \n",
    "        - book_id (String) : Unique identified for the book\n",
    "        - book_rating (Integer) : A value between 0 and 10\n",
    "        - reader_id (String) : Unique identifier for the user\n",
    "        - book_genre (Integer) : An integer representing a genre for the book, \n",
    "                                 value is between 1 and 15, indicating that \n",
    "                                 there are 15 unique genres. Each book can only\n",
    "                                 have 1 genre\n",
    "        - author_id (String) : Unique identifier for the author of the book\n",
    "        - num_pages (Integer) : Random value between 70 and 500\n",
    "        - publisher_id (String) : A unique identifier for the publisher of the book\n",
    "        - publish_year (Integer) : The year of book publishing\n",
    "        - book_price (Integer) : The sale price of the book\n",
    "        - text_lang (Integer) : The language of the book - returns an integer which \n",
    "                                is mapped to some language\n",
    "        \n",
    "    params:\n",
    "        n_books (Integer) : The number of books you want the dataset to have\n",
    "        n_genres (Integer) : Number of genres to be chosen from\n",
    "        n_authors (Integer) : Number of authors to be generated\n",
    "        n_publishers (Integer) : Number of publishers for the dataset\n",
    "        n_readers (Integer) : Number of readers for the dataset\n",
    "        dataset_size (Integer) : The number of rows to be generated \n",
    "        \n",
    "    example:\n",
    "        data = generate_data()\n",
    "    '''\n",
    "    \n",
    "    d = pd.DataFrame(\n",
    "        {\n",
    "            'book_id' : [randint(1, n_books) for _ in range(dataset_size)],\n",
    "            'author_id' : [randint(1, n_authors) for _ in range(dataset_size)],\n",
    "            'book_genre' : [randint(1, n_genres) for _ in range(dataset_size)],\n",
    "            'reader_id' : [randint(1, n_readers) for _ in range(dataset_size)],\n",
    "            'num_pages' : [randint(75, 700) for _ in range(dataset_size)],\n",
    "            'book_rating' : [randint(1, 10) for _ in range(dataset_size)],\n",
    "            'publisher_id' : [randint(1, n_publishers) for _ in range(dataset_size)],\n",
    "            'publish_year' : [randint(2000, 2021) for _ in range(dataset_size)],\n",
    "            'book_price' : [randint(1, 200) for _ in range(dataset_size)],\n",
    "            'text_lang' : [randint(1,7) for _ in range(dataset_size)]\n",
    "        }\n",
    "    ).drop_duplicates()\n",
    "    return d\n",
    "  \n",
    "d = generate_data(dataset_size = 100000)\n",
    "# d.to_csv('data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbbd2d93-3852-4a23-ae70-de27d49e2a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>book_genre</th>\n",
       "      <th>reader_id</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>book_rating</th>\n",
       "      <th>publisher_id</th>\n",
       "      <th>publish_year</th>\n",
       "      <th>book_price</th>\n",
       "      <th>text_lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1688</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>23269</td>\n",
       "      <td>593</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2001</td>\n",
       "      <td>174</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>852</td>\n",
       "      <td>425</td>\n",
       "      <td>4</td>\n",
       "      <td>12381</td>\n",
       "      <td>341</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>2010</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1742</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>25542</td>\n",
       "      <td>228</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>2006</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>182</td>\n",
       "      <td>428</td>\n",
       "      <td>4</td>\n",
       "      <td>28850</td>\n",
       "      <td>392</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>2012</td>\n",
       "      <td>92</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1857</td>\n",
       "      <td>383</td>\n",
       "      <td>8</td>\n",
       "      <td>12336</td>\n",
       "      <td>563</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>2000</td>\n",
       "      <td>122</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id  author_id  book_genre  reader_id  num_pages  book_rating  \\\n",
       "0     1688         65           3      23269        593            3   \n",
       "1      852        425           4      12381        341            5   \n",
       "2     1742         65          10      25542        228           10   \n",
       "3      182        428           4      28850        392            9   \n",
       "4     1857        383           8      12336        563            6   \n",
       "\n",
       "   publisher_id  publish_year  book_price  text_lang  \n",
       "0             7          2001         174          6  \n",
       "1            38          2010          12          3  \n",
       "2            50          2006          50          4  \n",
       "3            36          2012          92          5  \n",
       "4            21          2000         122          4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370ca25b-9215-4e62-892c-d6a6c716f059",
   "metadata": {},
   "source": [
    "## Train Model Normally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80f81c26-7070-4896-bd93-3f1da62f9018",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_features = ['num_pages', 'book_rating', 'book_price', 'text_lang']\n",
    "genre_target = 'book_genre'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18c2fecf-729b-4bd9-bfa1-e711fbf40828",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = d[genre_features].values\n",
    "y = d[genre_target].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, \n",
    "    y, \n",
    "    test_size = 0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07fbaca6-95af-48f6-a235-535daa694645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model\n",
      "CPU times: user 41.2 s, sys: 320 ms, total: 41.5 s\n",
      "Wall time: 41.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Training Model\")\n",
    "# instantiate the model (using the default parameters)\n",
    "gen_mdl = GradientBoostingClassifier()\n",
    "\n",
    "# fit the model with data\n",
    "gen_mdl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf8484c8-4373-4b1c-9cc9-dc053766fc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.10      0.11      0.11      3047\n",
      "           2       0.10      0.14      0.12      2934\n",
      "           3       0.10      0.08      0.09      3023\n",
      "           4       0.10      0.13      0.11      2987\n",
      "           5       0.10      0.09      0.09      3029\n",
      "           6       0.10      0.13      0.11      3047\n",
      "           7       0.09      0.08      0.09      2948\n",
      "           8       0.11      0.10      0.11      3042\n",
      "           9       0.09      0.06      0.07      2950\n",
      "          10       0.10      0.07      0.09      2993\n",
      "\n",
      "    accuracy                           0.10     30000\n",
      "   macro avg       0.10      0.10      0.10     30000\n",
      "weighted avg       0.10      0.10      0.10     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##perform classification and prediction on samples in tf_test\n",
    "predicted_mdl = gen_mdl.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predicted_mdl))\n",
    "report = classification_report(y_test, predicted_mdl, output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bed9e5f-2856-4958-b994-84afeefe00d2",
   "metadata": {},
   "source": [
    "## Train Model Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f43f0116-f02a-41c6-9e37-9c2754fab39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_features = ['num_pages', 'book_rating', 'book_price', 'book_genre']\n",
    "lang_target = 'text_lang'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab45ce40-983b-4da1-8080-2e5a9d2f3a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = d[lang_features].values\n",
    "y = d[lang_target].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, \n",
    "    y, \n",
    "    test_size = 0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19998844-02bd-417c-b704-20219a615ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model\n",
      "CPU times: user 8.95 s, sys: 440 ms, total: 9.39 s\n",
      "Wall time: 4.82 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_jobs=2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Training Model\")\n",
    "# instantiate the model (using the default parameters)\n",
    "lang_mdl = RandomForestClassifier(n_jobs = 2)\n",
    "\n",
    "# fit the model with data\n",
    "lang_mdl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5c42636-6004-412d-af10-f98259728feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.14      0.14      0.14      4292\n",
      "           2       0.14      0.15      0.15      4313\n",
      "           3       0.15      0.14      0.14      4270\n",
      "           4       0.15      0.14      0.15      4363\n",
      "           5       0.15      0.14      0.14      4352\n",
      "           6       0.14      0.15      0.15      4251\n",
      "           7       0.14      0.14      0.14      4159\n",
      "\n",
      "    accuracy                           0.14     30000\n",
      "   macro avg       0.14      0.14      0.14     30000\n",
      "weighted avg       0.14      0.14      0.14     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##perform classification and prediction on samples in tf_test\n",
    "predicted_mdl = lang_mdl.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predicted_mdl))\n",
    "report = classification_report(y_test, predicted_mdl, output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccf52ea-9c38-4192-9639-8ca75a40771b",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "879de595-1dcc-4125-a77d-ab819855181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# evaluate the model\n",
    "n_scores = cross_val_score(\n",
    "    lang_mdl,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    scoring='accuracy',\n",
    "    cv=4, \n",
    "    n_jobs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d26f7d09-e646-4c14-8a58-dbf74920b006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.4 ms, sys: 99 ms, total: 131 ms\n",
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# evaluate the model\n",
    "n_scores = cross_val_score(\n",
    "    lang_mdl,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    scoring='accuracy',\n",
    "    cv=4,\n",
    "    n_jobs=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65b7f7d-28dd-4e68-8b07-60eb5e4bf3d0",
   "metadata": {},
   "source": [
    "## Parallelize Model Predictions - Singular Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcc49e5-47aa-406e-9ffe-614f26e51573",
   "metadata": {},
   "source": [
    "### Predict Normally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29efba11-7fd5-4253-9cb6-bf47ddef923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, feature_cols, clf, pred_col):\n",
    "    '''\n",
    "    This function will generate predictions given a dataset, the associated features and a model.\n",
    "    \n",
    "    params:\n",
    "        data (DataFrame) : The dataset which holds the features\n",
    "        feature_cols (List -> String) : List of column names in data corresponding to the model features\n",
    "        clf (Model) : The classification model which generates the predictions\n",
    "        pred_col (String) : The name of the column you want to store the predictions under in data\n",
    "        \n",
    "    returns:\n",
    "        This function will add a column to the input dataset associated to the predictions generated\n",
    "    \n",
    "    example:\n",
    "        >> predict(\n",
    "            data = df,\n",
    "            feature_col = lang_features,\n",
    "            pred_col = 'lang_prediction'\n",
    "        )\n",
    "    '''\n",
    "    ft = data[feature_cols].values\n",
    "    res = clf.predict(ft)\n",
    "    data[pred_col] = res\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c25eed94-a934-4f53-b3ef-77a17d7228b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.46 s, sys: 256 ms, total: 2.72 s\n",
      "Wall time: 1.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# normal predictions\n",
    "res = predict(\n",
    "    data = d,\n",
    "    feature_cols = lang_features,\n",
    "    clf = lang_mdl,\n",
    "    pred_col = 'lang_prediction'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42645235-8d56-4d71-a343-1612fe912d80",
   "metadata": {},
   "source": [
    "### Predict in Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4a21faa-946b-4aa0-b0a7-bacc78865af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_pred(fn, data, feature_cols, clf, pred_col, n_cores):\n",
    "    '''\n",
    "    This function will parallelize the prediction process such that the data is split into\n",
    "    n components (n is defined based on n_cores) and passed onto the model.\n",
    "    \n",
    "    params:\n",
    "        fn (Function) : The function you want to parallelize\n",
    "        data (DataFrame) : The dataset holding the features for the model\n",
    "        feature_cols (List -> String) : List of column names in data corresponding to the model features\n",
    "        clf (Model) : The  model which generates the predictions\n",
    "        pred_col (String) : The name of the column you want to store the predictions under in data\n",
    "        n_cores (Integer) : The number of cores you want to use\n",
    "    \n",
    "    returns:\n",
    "        This function will return the result of the input function\n",
    "        \n",
    "    example:\n",
    "        parallel_pred(\n",
    "            fn = predict, \n",
    "            data = d,\n",
    "            feature_cols = lang_features,\n",
    "            clf = lang_mdl,\n",
    "            pred_col = 'parallel_lang_pred',\n",
    "            n_cores = 4\n",
    "        )\n",
    "    '''\n",
    "    if cpu_count() < n_cores:\n",
    "        raise ValueError(\"The number of CPU's specified exceed the amount available\")\n",
    "\n",
    "    df_list = np.array_split(data, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    res = pool.map(partial(\n",
    "        fn, \n",
    "        feature_cols = feature_cols, \n",
    "        clf = clf, \n",
    "        pred_col = pred_col\n",
    "    ), df_list)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return pd.concat(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10298459-0890-4dbe-b4cf-4426e6372b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# parallel predictions\n",
    "res = parallel_pred(\n",
    "    fn = predict, \n",
    "    data = d,\n",
    "    feature_cols = lang_features,\n",
    "    clf = lang_mdl,\n",
    "    pred_col = 'parallel_lang_pred',\n",
    "    n_cores = 4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60a2443-1715-4d3a-9c51-aab9ab41981a",
   "metadata": {},
   "source": [
    "## Parallelize Model Predictions - Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f2875e1-37f2-4273-934f-708a39d14c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [gen_mdl, lang_mdl]\n",
    "features = [genre_features, lang_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548b5154-711c-4900-bfd7-04d5db199623",
   "metadata": {},
   "source": [
    "### Predict Normally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6647663e-d216-43b9-ac83-ab9eb2b4d963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_predcit(data, models, features = features, pred_col = 'prediction_{}'):\n",
    "    '''\n",
    "    This function will outline how to generate predictions associated to multiple\n",
    "    models when passing in the same dataset.\n",
    "    \n",
    "    params:\n",
    "        data (DataFrame) : The dataframe holding the feature data for the model\n",
    "        feature_col (String) : List of columns in the dataset necessary\n",
    "                                        to generate predictions\n",
    "        models (List) : Key is the target the model is predicting for, values\n",
    "                        are the associated models.\n",
    "        pred_col (String): The name of the column you want storing the results\n",
    "        \n",
    "    returns:\n",
    "        This function will return the input dataframe with additional columns \n",
    "        corresponding to the predictions generated from all the models passed.\n",
    "        \n",
    "    example:\n",
    "        multi_predcit(\n",
    "            data = res,\n",
    "            feature_col = 'stopwordless_content',\n",
    "            models = models,\n",
    "            pred_col = 'prediction_{}'\n",
    "        )\n",
    "    '''\n",
    "\n",
    "    for i, (ft_cols, mdl) in enumerate(zip(features, models)):\n",
    "        ft = data[ft_cols].values\n",
    "        res = mdl.predict(ft)\n",
    "        data[pred_col.format(i)] = res\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50b31e3d-a480-48fb-bb84-23970f4ad7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.39 s, sys: 301 ms, total: 3.7 s\n",
      "Wall time: 2.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# predict normally\n",
    "res = multi_predcit(\n",
    "    data = d,\n",
    "    features = features,\n",
    "    models = models,\n",
    "    pred_col = 'prediction_{}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca4d07f-d338-44ea-8f40-35ffccb3edfc",
   "metadata": {},
   "source": [
    "### Predict Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f144d6b0-eca2-45a3-8661-421473013074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_multi(fn, data, models, features, n_cores):\n",
    "    '''\n",
    "    This function will parallelize the input function so that a model is allocated to each core and \n",
    "    predictions are generated in parallel. \n",
    "    \n",
    "    params:\n",
    "        fn (Function) : The function you want to parallelize\n",
    "        data (DataFrame) : The dataset holding the features\n",
    "        feature_col (String) : The column corresponding to the article content\n",
    "        models (List) : The list of models \n",
    "        pred_col (String) : The name of the column you want to store the results in\n",
    "        n_cores (Integer) : The number of cores you want to parallelize with\n",
    "        \n",
    "    returns:\n",
    "        This function will return the input dataframe with additional columns, 1 \n",
    "        corresponding to each of the models\n",
    "        \n",
    "    example: \n",
    "        parallel_multi(\n",
    "            fn = multi_predcit,\n",
    "            data = res,\n",
    "            models = models_list,\n",
    "            features = features,\n",
    "            n_cores = 2\n",
    "        )\n",
    "    '''\n",
    "    \n",
    "    mdl_split = np.array_split(models, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    res = pool.map(partial(fn, data, features), mdl_split)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248a9060-15cc-463c-8f70-14a9e314d0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# predict parallel\n",
    "res = parallel_multi(\n",
    "    fn = multi_predcit,\n",
    "    data = d,\n",
    "    models = models,\n",
    "    features = features,\n",
    "    n_cores = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe740d1-cbb3-4530-a402-dd0605b391d0",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
