{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4a8291c-904a-4d8f-be10-82a452e80c40",
   "metadata": {},
   "source": [
    "# Parallelize Sci-Kit Learn Models & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e77f512-c05f-4e8d-90a3-6909ca018014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from random import randint\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing import cpu_count\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7079187e-7ef2-4616-b4d0-711c075aaf85",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac520aa4-a9a6-4c51-af7c-d30e8b3f7f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_books = 3000, n_genres = 10, n_authors = 450, n_publishers = 50, n_readers = 30000, dataset_size = 100000):\n",
    "    '''\n",
    "    This function will generate a dataset with features associated to\n",
    "    book data set. The dataset will have the following columns : \n",
    "        - book_id (String) : Unique identified for the book\n",
    "        - book_rating (Integer) : A value between 0 and 10\n",
    "        - reader_id (String) : Unique identifier for the user\n",
    "        - book_genre (Integer) : An integer representing a genre for the book, \n",
    "                                 value is between 1 and 15, indicating that \n",
    "                                 there are 15 unique genres. Each book can only\n",
    "                                 have 1 genre\n",
    "        - author_id (String) : Unique identifier for the author of the book\n",
    "        - num_pages (Integer) : Random value between 70 and 500\n",
    "        - publisher_id (String) : A unique identifier for the publisher of the book\n",
    "        - publish_year (Integer) : The year of book publishing\n",
    "        - book_price (Integer) : The sale price of the book\n",
    "        - text_lang (Integer) : The language of the book - returns an integer which \n",
    "                                is mapped to some language\n",
    "        \n",
    "    params:\n",
    "        n_books (Integer) : The number of books you want the dataset to have\n",
    "        n_genres (Integer) : Number of genres to be chosen from\n",
    "        n_authors (Integer) : Number of authors to be generated\n",
    "        n_publishers (Integer) : Number of publishers for the dataset\n",
    "        n_readers (Integer) : Number of readers for the dataset\n",
    "        dataset_size (Integer) : The number of rows to be generated \n",
    "        \n",
    "    example:\n",
    "        data = generate_data()\n",
    "    '''\n",
    "    \n",
    "    d = pd.DataFrame(\n",
    "        {\n",
    "            'book_id' : [randint(1, n_books) for _ in range(dataset_size)],\n",
    "            'author_id' : [randint(1, n_authors) for _ in range(dataset_size)],\n",
    "            'book_genre' : [randint(1, n_genres) for _ in range(dataset_size)],\n",
    "            'reader_id' : [randint(1, n_readers) for _ in range(dataset_size)],\n",
    "            'num_pages' : [randint(75, 700) for _ in range(dataset_size)],\n",
    "            'book_rating' : [randint(1, 10) for _ in range(dataset_size)],\n",
    "            'publisher_id' : [randint(1, n_publishers) for _ in range(dataset_size)],\n",
    "            'publish_year' : [randint(2000, 2021) for _ in range(dataset_size)],\n",
    "            'book_price' : [randint(1, 200) for _ in range(dataset_size)],\n",
    "            'text_lang' : [randint(1,7) for _ in range(dataset_size)]\n",
    "        }\n",
    "    ).drop_duplicates()\n",
    "    return d\n",
    "  \n",
    "d = generate_data(dataset_size = 100000)\n",
    "# d.to_csv('data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5679a3f-53e0-4f77-9cde-dde18dbedb9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>book_genre</th>\n",
       "      <th>reader_id</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>book_rating</th>\n",
       "      <th>publisher_id</th>\n",
       "      <th>publish_year</th>\n",
       "      <th>book_price</th>\n",
       "      <th>text_lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2397</td>\n",
       "      <td>356</td>\n",
       "      <td>2</td>\n",
       "      <td>24324</td>\n",
       "      <td>365</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>2008</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1797</td>\n",
       "      <td>209</td>\n",
       "      <td>7</td>\n",
       "      <td>21066</td>\n",
       "      <td>679</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>2009</td>\n",
       "      <td>77</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1284</td>\n",
       "      <td>381</td>\n",
       "      <td>7</td>\n",
       "      <td>20818</td>\n",
       "      <td>298</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>2007</td>\n",
       "      <td>180</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2376</td>\n",
       "      <td>416</td>\n",
       "      <td>2</td>\n",
       "      <td>28382</td>\n",
       "      <td>511</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>2020</td>\n",
       "      <td>164</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2927</td>\n",
       "      <td>272</td>\n",
       "      <td>2</td>\n",
       "      <td>28206</td>\n",
       "      <td>255</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>2010</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id  author_id  book_genre  reader_id  num_pages  book_rating  \\\n",
       "0     2397        356           2      24324        365            8   \n",
       "1     1797        209           7      21066        679            8   \n",
       "2     1284        381           7      20818        298           10   \n",
       "3     2376        416           2      28382        511            7   \n",
       "4     2927        272           2      28206        255            3   \n",
       "\n",
       "   publisher_id  publish_year  book_price  text_lang  \n",
       "0            25          2008          56          3  \n",
       "1            17          2009          77          4  \n",
       "2            21          2007         180          7  \n",
       "3            32          2020         164          4  \n",
       "4            44          2010         135          1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f21d4fc-0b8d-48f7-a72a-28a58f5c67ee",
   "metadata": {},
   "source": [
    "## Train Model Normally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c7f7498-40cf-4aef-8e97-bd8d4fcf6fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_features = ['num_pages', 'book_rating', 'book_price', 'text_lang']\n",
    "genre_target = 'book_genre'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cc465f2-2957-47e8-a03f-5ee48e768f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = d[genre_features].values\n",
    "y = d[genre_target].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, \n",
    "    y, \n",
    "    test_size = 0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "892c01b0-8470-409a-bada-082424cb2f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model\n",
      "CPU times: user 54.4 s, sys: 71.9 ms, total: 54.5 s\n",
      "Wall time: 54.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Training Model\")\n",
    "# instantiate the model (using the default parameters)\n",
    "gen_mdl = GradientBoostingClassifier()\n",
    "\n",
    "# fit the model with data\n",
    "gen_mdl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dedb36e-70a3-4fb0-8532-c8564d7b9018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.10      0.08      0.09      2899\n",
      "           2       0.09      0.09      0.09      2974\n",
      "           3       0.11      0.08      0.09      2990\n",
      "           4       0.11      0.10      0.10      3025\n",
      "           5       0.10      0.13      0.11      2967\n",
      "           6       0.10      0.12      0.11      3024\n",
      "           7       0.10      0.09      0.09      2993\n",
      "           8       0.10      0.08      0.09      3026\n",
      "           9       0.09      0.10      0.10      3037\n",
      "          10       0.11      0.13      0.12      3065\n",
      "\n",
      "    accuracy                           0.10     30000\n",
      "   macro avg       0.10      0.10      0.10     30000\n",
      "weighted avg       0.10      0.10      0.10     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##perform classification and prediction on samples in tf_test\n",
    "predicted_mdl = gen_mdl.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predicted_mdl))\n",
    "report = classification_report(y_test, predicted_mdl, output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e8386d-15ae-4067-b48d-b1a7c2e449f3",
   "metadata": {},
   "source": [
    "## Train Model Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6df1a447-ff43-4d5a-a611-5abe5ce229af",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_features = ['num_pages', 'book_rating', 'book_price', 'book_genre']\n",
    "lang_target = 'text_lang'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "749ecdca-1019-47a4-a6e5-c137d6a676a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = d[lang_features].values\n",
    "y = d[lang_target].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, \n",
    "    y, \n",
    "    test_size = 0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62155dd1-2ac9-4664-9dc4-e4783560059c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model\n",
      "CPU times: user 17 s, sys: 439 ms, total: 17.4 s\n",
      "Wall time: 8.96 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=2,\n",
       "                       oob_score=False, random_state=None, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Training Model\")\n",
    "# instantiate the model (using the default parameters)\n",
    "lang_mdl = RandomForestClassifier(n_jobs = 2)\n",
    "\n",
    "# fit the model with data\n",
    "lang_mdl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "234ca5fe-e051-4317-b3a3-f3ec32873334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.15      0.15      0.15      4258\n",
      "           2       0.14      0.15      0.14      4277\n",
      "           3       0.15      0.14      0.15      4391\n",
      "           4       0.14      0.13      0.13      4275\n",
      "           5       0.14      0.14      0.14      4254\n",
      "           6       0.14      0.13      0.14      4255\n",
      "           7       0.14      0.13      0.13      4290\n",
      "\n",
      "    accuracy                           0.14     30000\n",
      "   macro avg       0.14      0.14      0.14     30000\n",
      "weighted avg       0.14      0.14      0.14     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##perform classification and prediction on samples in tf_test\n",
    "predicted_mdl = lang_mdl.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predicted_mdl))\n",
    "report = classification_report(y_test, predicted_mdl, output_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96b6061-05d5-493a-ba02-9919a16c5508",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3edb50e6-1c62-468f-9ce6-636bacdec021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.26 s, sys: 1.38 s, total: 7.64 s\n",
      "Wall time: 34.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# evaluate the model\n",
    "n_scores = cross_val_score(\n",
    "    lang_mdl,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    scoring='accuracy',\n",
    "    cv=4, \n",
    "    n_jobs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e60aab8-be7d-47d4-a0f4-7345e439e88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.1 ms, sys: 0 ns, total: 33.1 ms\n",
      "Wall time: 28.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# evaluate the model\n",
    "n_scores = cross_val_score(\n",
    "    lang_mdl,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    scoring='accuracy',\n",
    "    cv=4,\n",
    "    n_jobs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856848c5-b5b3-428e-b01e-892386bd47a3",
   "metadata": {},
   "source": [
    "## Parallelize Model Predictions - Singular Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4282eda-d105-4939-b8ca-f4e2edc2758f",
   "metadata": {},
   "source": [
    "### Predict Normally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cd33d1f-e457-43e1-86b7-33a1b7fdb7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, feature_cols, clf, pred_col):\n",
    "    '''\n",
    "    This function will generate predictions given a dataset, the associated features and a model.\n",
    "    \n",
    "    params:\n",
    "        data (DataFrame) : The dataset which holds the features\n",
    "        feature_cols (List -> String) : List of column names in data corresponding to the model features\n",
    "        clf (Model) : The classification model which generates the predictions\n",
    "        pred_col (String) : The name of the column you want to store the predictions under in data\n",
    "        \n",
    "    returns:\n",
    "        This function will add a column to the input dataset associated to the predictions generated\n",
    "    \n",
    "    example:\n",
    "        >> predict(\n",
    "            data = df,\n",
    "            feature_col = lang_features,\n",
    "            pred_col = 'lang_prediction'\n",
    "        )\n",
    "    '''\n",
    "    ft = data[feature_cols].values\n",
    "    res = clf.predict(ft)\n",
    "    data[pred_col] = res\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d6484dd-59ee-4683-aecb-86662cb4a19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.47 s, sys: 35.5 ms, total: 4.5 s\n",
      "Wall time: 2.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# normal predictions\n",
    "res = predict(\n",
    "    data = d,\n",
    "    feature_cols = lang_features,\n",
    "    clf = lang_mdl,\n",
    "    pred_col = 'lang_prediction'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b175fc6-9127-41ba-846d-ade1cc261fa9",
   "metadata": {},
   "source": [
    "### Predict in Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29a33aa5-f45c-456c-bf51-3cb89a21c7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_pred(fn, data, feature_cols, clf, pred_col, n_cores):\n",
    "    '''\n",
    "    This function will parallelize the prediction process such that the data is split into\n",
    "    n components (n is defined based on n_cores) and passed onto the model.\n",
    "    \n",
    "    params:\n",
    "        fn (Function) : The function you want to parallelize\n",
    "        data (DataFrame) : The dataset holding the features for the model\n",
    "        feature_cols (List -> String) : List of column names in data corresponding to the model features\n",
    "        clf (Model) : The  model which generates the predictions\n",
    "        pred_col (String) : The name of the column you want to store the predictions under in data\n",
    "        n_cores (Integer) : The number of cores you want to use\n",
    "    \n",
    "    returns:\n",
    "        This function will return the result of the input function\n",
    "        \n",
    "    example:\n",
    "        parallel_pred(\n",
    "            fn = predict, \n",
    "            data = d,\n",
    "            feature_cols = lang_features,\n",
    "            clf = lang_mdl,\n",
    "            pred_col = 'parallel_lang_pred',\n",
    "            n_cores = 4\n",
    "        )\n",
    "    '''\n",
    "    if cpu_count() < n_cores:\n",
    "        raise ValueError(\"The number of CPU's specified exceed the amount available\")\n",
    "\n",
    "    df_list = np.array_split(data, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    res = pool.map(partial(\n",
    "        fn, \n",
    "        feature_cols = feature_cols, \n",
    "        clf = clf, \n",
    "        pred_col = pred_col\n",
    "    ), df_list)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return pd.concat(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "890cbcdf-fdef-48f7-a620-2ac5c79ece25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 894 ms, sys: 1.79 s, total: 2.68 s\n",
      "Wall time: 7.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# parallel predictions\n",
    "res = parallel_pred(\n",
    "    fn = predict, \n",
    "    data = d,\n",
    "    feature_cols = lang_features,\n",
    "    clf = lang_mdl,\n",
    "    pred_col = 'parallel_lang_pred',\n",
    "    n_cores = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6206db3-c0c5-44ef-ac14-ceeeda1132cf",
   "metadata": {},
   "source": [
    "## Parallelize Model Predictions - Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6904a1e-40f3-4ae5-a934-ca81ed48c4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [gen_mdl, lang_mdl]\n",
    "features = [genre_features, lang_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94d4bf09-54cc-42f6-bbb2-6c679d307059",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = [[gen_mdl, genre_features, 'genre'], [lang_mdl, lang_features, 'lang']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0ed4c0-312e-4194-be15-df2fec21c5d5",
   "metadata": {},
   "source": [
    "### Predict Normally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "370368c0-4911-46d4-bc24-72347f8d55f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_predcit(data, models_data, pred_col = 'prediction_{}'):\n",
    "    '''\n",
    "    This function will outline how to generate predictions associated to multiple\n",
    "    models when passing in the same dataset.\n",
    "    \n",
    "    params:\n",
    "        data (DataFrame) : The dataframe holding the feature data for the model\n",
    "        models_data (List -> List) : Nested list associated with the model, \n",
    "                                     feature columns and the name of the target\n",
    "        pred_col (String): The name of the column you want storing the results\n",
    "        \n",
    "    returns:\n",
    "        This function will return the input dataframe with additional columns \n",
    "        corresponding to the predictions generated from all the models passed.\n",
    "        \n",
    "    example:\n",
    "        multi_predcit(\n",
    "            data = d,\n",
    "            models_data = model_data,\n",
    "            pred_col = 'prediction_{}'\n",
    "        )\n",
    "    '''\n",
    "\n",
    "    for i in models_data:\n",
    "        mdl = i[0]\n",
    "        ft_cols = i[1]\n",
    "        target = i[2]\n",
    "        ft = data[ft_cols].values\n",
    "        res = mdl.predict(ft)\n",
    "        data[pred_col.format(target)] = res\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db80f8f6-1d09-4773-98cd-4b2a6ae59ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.61 s, sys: 27.8 ms, total: 5.64 s\n",
      "Wall time: 3.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# predict normally\n",
    "res = multi_predcit(\n",
    "    data = d,\n",
    "    models_data = model_data,\n",
    "    pred_col = 'prediction_{}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c26eaf5-691b-490a-8a7f-76eb6a616d23",
   "metadata": {},
   "source": [
    "### Predict Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "400ac73a-ae30-458a-9378-6b4a09263af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_multi(fn, data, model_data, n_cores):\n",
    "    '''\n",
    "    This function will parallelize the input function so that a model is allocated to each core and \n",
    "    predictions are generated in parallel. \n",
    "    \n",
    "    params:\n",
    "        fn (Function) : The function you want to parallelize\n",
    "        data (DataFrame) : The dataset holding the features\n",
    "        models_data (List -> List) : Nested list associated with the model, \n",
    "                                     feature columns and the name of the target\n",
    "        n_cores (Integer) : The number of cores you want to parallelize with\n",
    "        \n",
    "    returns:\n",
    "        This function will return the input dataframe with additional columns, 1 \n",
    "        corresponding to each of the models\n",
    "        \n",
    "    example: \n",
    "        parallel_multi(\n",
    "            fn = multi_predcit,\n",
    "            data = d,\n",
    "            model_data = model_data,\n",
    "            n_cores = 2\n",
    "        )\n",
    "    '''\n",
    "    \n",
    "    mdl_split = np.array_split(model_data, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    res = pool.map(partial(fn, data), mdl_split)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ceb06b52-c2d3-411c-b356-a44fd08ab3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 433 ms, sys: 1.19 s, total: 1.63 s\n",
      "Wall time: 7.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# predict parallel\n",
    "res = parallel_multi(\n",
    "    fn = multi_predcit,\n",
    "    data = d,\n",
    "    model_data = model_data,\n",
    "    n_cores = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09456651-9233-4b65-9065-803e82216341",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
