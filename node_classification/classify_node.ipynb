{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "168de318-3817-4a4e-92bf-6868424c3898",
   "metadata": {},
   "source": [
    "# Node Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b49769-f6f6-4fce-9c11-75d049198bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install arxiv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0149edf3-39ce-4acf-a6f0-a5ed481ca5e4",
   "metadata": {},
   "source": [
    "You can install the arxiv package in Python with the following command:   \n",
    "`pip install arxiv`   \n",
    "or follow the instructions here : https://pypi.org/project/arxiv/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd226a28-bf3a-4b14-80de-2193c6a851b2",
   "metadata": {},
   "source": [
    "## What is Node Classification?  \n",
    "Node classification is a common application of machine learning on graphs. Generally, you train a classification model to learn which class a certain node is apart of. This approach is common for both binary and multiclass classification [1]. In binary classification you're dealing with two different classes wheras multiclass classificaiton you are dealing with more than 2 different classes. In the context of this tutorial, we are going to use node2vec to generate node embeddings of the network. Node2vec is designed to preserve the initial structure within the original graph.  \n",
    "\n",
    "## Problem Statement   \n",
    "Given the main topic of research papers published on arXiv, we will build a pipeline which will train a model to classify a research paper based on its main topic.  \n",
    "\n",
    "## Solution Architecture  \n",
    "We will being by creating a network with nodes as articles and edges connecting these nodes based on the main topic connecting a pair of articles. After creating this network we will use node2vec to generate node embeddings associated to each artile. Finally, we can map the node embeddings associated to each node to its associated topic. The embeddings can be passed on as features and the main topic as the target to train a classification model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbf4a040-67f8-421b-aef3-2ccbac7f1946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import arxiv\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, confusion_matrix, classification_report\n",
    "from node2vec import Node2Vec as n2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1af08b4c-d203-4aa3-be20-2271b06d8827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "queries = [\n",
    "    'automl', 'machinelearning', 'data', 'phyiscs','mathematics', 'recommendation system', 'nlp', 'neural networks'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c79e656-b9a1-4c8a-bc5c-016e1ab8b23b",
   "metadata": {},
   "source": [
    "## Fetch Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab49a7c-266f-4a48-b9de-92bb8f0d5e75",
   "metadata": {},
   "source": [
    "We want to hit th Arxiv API to gather some information about the latest research papers based on the queries we've identified above. This will allow us to then create a network from this research paper data and then we can try to classify nodes on that network. For the purposes of this article, I will search for a maximum of 1000 results per query, but you don't have to set yourself to the same constraints. The Arxiv API allows users to hit up to 300,000 results per query. The function outlined below will generate a CSV fetching the following information :\n",
    "'title', 'date', 'article_id', 'url', 'main_topic', 'all_topics', 'authors', 'year'\n",
    "You are able to fetch more information like the links, summary, article but I decided not to since those features won't really be used for the purposes of this analysis and tutorial.\n",
    "\n",
    "For reference to the Arxiv API, you can find their detailed documentation here : https://arxiv.org/help/api/user-manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "944f1ccb-69db-4c2f-a5a2-9361c5637d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_arxiv(queries, max_results = 100):\n",
    "    '''\n",
    "    This function will search arxiv associated to a set of queries and store\n",
    "    the latest 10000 (max_results) associated to that search.\n",
    "    \n",
    "    params:\n",
    "        queries (List -> Str) : A list of strings containing keywords you want\n",
    "                                to search on Arxiv\n",
    "        max_results (Int) : The maximum number of results you want to see associated\n",
    "                            to your search. Default value is 1000, capped at 300000\n",
    "                            \n",
    "    returns:\n",
    "        This function will return a DataFrame holding the following columns associated\n",
    "        to the queries the user has passed. \n",
    "            `title`, `date`, `article_id`, `url`, `main_topic`, `all_topics`\n",
    "    \n",
    "    example:\n",
    "        research_df = search_arxiv(\n",
    "            queries = ['automl', 'recommender system', 'nlp', 'data science'],\n",
    "            max_results = 10000\n",
    "        )\n",
    "    '''\n",
    "    d = []\n",
    "    searches = []\n",
    "    # hitting the API\n",
    "    for query in queries:\n",
    "        search = arxiv.Search(\n",
    "          query = query,\n",
    "          max_results = max_results,\n",
    "          sort_by = arxiv.SortCriterion.SubmittedDate,\n",
    "          sort_order = arxiv.SortOrder.Descending\n",
    "        )\n",
    "        searches.append(search)\n",
    "    \n",
    "    # Converting search result into df\n",
    "    for search in searches:\n",
    "        for res in search.results():\n",
    "            data = {\n",
    "                'title' : res.title,\n",
    "                'date' : res.published,\n",
    "                'article_id' : res.entry_id,\n",
    "                'url' : res.pdf_url,\n",
    "                'main_topic' : res.primary_category,\n",
    "                'all_topics' : res.categories,\n",
    "                'authors' : res.authors\n",
    "            }\n",
    "            d.append(data)\n",
    "        \n",
    "    d = pd.DataFrame(d)\n",
    "    d['year'] = pd.DatetimeIndex(d['date']).year\n",
    "    \n",
    "    # change article id from url to integer\n",
    "    unique_article_ids = d.article_id.unique()\n",
    "    article_mapping = {art:idx for idx,art in enumerate(unique_article_ids)}\n",
    "    d['article_id'] = d['article_id'].map(article_mapping)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00a0f9af-524d-4370-bce7-f8c6855152dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.9 s, sys: 188 ms, total: 3.09 s\n",
      "Wall time: 1min 9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1546, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "research_df = search_arxiv(\n",
    "    queries = queries,\n",
    "    max_results = 250\n",
    ")\n",
    "research_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98d9f4e-3e3f-4f80-9049-ca44751005bb",
   "metadata": {},
   "source": [
    "If you're having trouble querying the data, for reproducibility purposes, the CSV I used for the analysis conducted in this article was uploaded to my GitHub which you can find here. https://github.com/vatsal220/medium_articles/blob/main/link_prediction/data/arxiv_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7886d3-e135-495e-a96a-aa141cf51fae",
   "metadata": {},
   "source": [
    "## Generate Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aca878-fac8-4812-9c2b-f181efca75a4",
   "metadata": {},
   "source": [
    "Now that we've fetched the data using the Arxiv API, we can generate a network. The network will have the following structure, nodes will be the article_ids and the edges will be all topics connecting a pair of articles. For example, article_id 1 with the following topics astro-physics, and `stats` can be connected to article_id 10 with the topic stats and article_id 7 with the topics `astro-physics`, `math`. This will be a multi-edge network where each edge will hold a weight of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c6e106a-ba56-4659-a188-772306d5c078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_network(df, node_col, edge_col):\n",
    "    '''\n",
    "    This function will generate a article to article network given an input DataFrame.\n",
    "    It will do so by creating an edge_dictionary where each key is going to be a node\n",
    "    referenced by unique values in node_col and the values will be a list of other nodes\n",
    "    connected to the key through the edge_col.\n",
    "    \n",
    "    params:\n",
    "        df (DataFrame) : The dataset which holds the node and edge columns\n",
    "        node_col (String) : The column name associated to the nodes of the network\n",
    "        edge_col (String) : The column name associated to the edges of the network\n",
    "        \n",
    "    returns:\n",
    "        A networkx graph corresponding to the input dataset\n",
    "        \n",
    "    example:\n",
    "        generate_network(\n",
    "            research_df,\n",
    "            node_col = 'article_id',\n",
    "            edge_col = 'main_topic'\n",
    "        )\n",
    "    '''\n",
    "    edge_dct = {}\n",
    "    for i,g in df.groupby(node_col):\n",
    "        topics = g[edge_col].unique()\n",
    "        edge_df = df[(df[node_col] != i) & (df[edge_col].isin(topics))]\n",
    "        edges = list(edge_df[node_col].unique())\n",
    "        edge_dct[i] = edges\n",
    "    \n",
    "    # create nx network\n",
    "    g = nx.Graph(edge_dct, create_using = nx.MultiGraph)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e739a71-2a1e-4dfd-aae1-620410bfca01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 898 ms, sys: 16.4 ms, total: 914 ms\n",
      "Wall time: 939 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tp_nx = generate_network(\n",
    "    research_df, \n",
    "    node_col = 'article_id', \n",
    "    edge_col = 'main_topic'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77bb39fb-b179-4108-8993-084b4156caba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 1350\n",
      "Number of edges: 66703\n",
      "Average degree:  98.8193\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(tp_nx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e5a6ab-eca7-46f1-91b0-49e96514ecf6",
   "metadata": {},
   "source": [
    "## Apply Node2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a4d822-2f96-426a-89dc-26e70d4eff50",
   "metadata": {},
   "source": [
    "This component will cover running node2vec on the graph generated above and creating the associated node embeddings for that network. These embeddings will play a crucial role coming up as they're the main features necessary for building a node classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23802c9a-b3a4-435b-b53d-4a01b88ac758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff885ca550e247e99acba383e1cca621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/1350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [00:27<00:00,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 20s, sys: 686 ms, total: 1min 21s\n",
      "Wall time: 1min 21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%time g_emb = n2v(tp_nx, dimensions=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3aff2d00-67dc-4a1b-9d09-b970f82088a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW = 1 # Node2Vec fit window\n",
    "MIN_COUNT = 1 # Node2Vec min. count\n",
    "BATCH_WORDS = 4 # Node2Vec batch words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38b5b5f3-4b58-4e42-b2ad-67e25b99364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = g_emb.fit(\n",
    "    window=WINDOW,\n",
    "    min_count=MIN_COUNT,\n",
    "    batch_words=BATCH_WORDS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06e2f2af-0938-4378-9304-c620faac9012",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_df = (\n",
    "    pd.DataFrame(\n",
    "        [mdl.wv.get_vector(str(n)) for n in tp_nx.nodes()],\n",
    "        index = tp_nx.nodes\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63a54708-bc49-4079-9683-fab39fa704a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.982184</td>\n",
       "      <td>-0.418723</td>\n",
       "      <td>0.648704</td>\n",
       "      <td>0.777569</td>\n",
       "      <td>1.278544</td>\n",
       "      <td>-0.682070</td>\n",
       "      <td>-0.140218</td>\n",
       "      <td>-0.352046</td>\n",
       "      <td>-0.154250</td>\n",
       "      <td>-0.430749</td>\n",
       "      <td>0.095327</td>\n",
       "      <td>0.495061</td>\n",
       "      <td>0.123365</td>\n",
       "      <td>-0.055955</td>\n",
       "      <td>-0.018547</td>\n",
       "      <td>1.452183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.009432</td>\n",
       "      <td>-0.445544</td>\n",
       "      <td>0.703062</td>\n",
       "      <td>0.828961</td>\n",
       "      <td>1.277971</td>\n",
       "      <td>-0.544692</td>\n",
       "      <td>-0.077958</td>\n",
       "      <td>-0.374260</td>\n",
       "      <td>-0.158336</td>\n",
       "      <td>-0.590008</td>\n",
       "      <td>0.082956</td>\n",
       "      <td>0.530169</td>\n",
       "      <td>0.090699</td>\n",
       "      <td>-0.133567</td>\n",
       "      <td>-0.039257</td>\n",
       "      <td>1.416739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.964131</td>\n",
       "      <td>-0.389936</td>\n",
       "      <td>0.690117</td>\n",
       "      <td>0.866124</td>\n",
       "      <td>1.258624</td>\n",
       "      <td>-0.660620</td>\n",
       "      <td>-0.128217</td>\n",
       "      <td>-0.401386</td>\n",
       "      <td>-0.151005</td>\n",
       "      <td>-0.549149</td>\n",
       "      <td>0.070321</td>\n",
       "      <td>0.506534</td>\n",
       "      <td>0.066263</td>\n",
       "      <td>-0.155309</td>\n",
       "      <td>-0.049878</td>\n",
       "      <td>1.412636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.948457</td>\n",
       "      <td>-0.382216</td>\n",
       "      <td>0.711337</td>\n",
       "      <td>0.833575</td>\n",
       "      <td>1.244138</td>\n",
       "      <td>-0.752523</td>\n",
       "      <td>-0.095578</td>\n",
       "      <td>-0.392389</td>\n",
       "      <td>-0.137476</td>\n",
       "      <td>-0.570683</td>\n",
       "      <td>0.031246</td>\n",
       "      <td>0.557270</td>\n",
       "      <td>0.073654</td>\n",
       "      <td>-0.155646</td>\n",
       "      <td>0.006648</td>\n",
       "      <td>1.400579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.910574</td>\n",
       "      <td>-0.306636</td>\n",
       "      <td>0.748167</td>\n",
       "      <td>0.808214</td>\n",
       "      <td>1.259955</td>\n",
       "      <td>-0.739075</td>\n",
       "      <td>-0.202448</td>\n",
       "      <td>-0.436149</td>\n",
       "      <td>-0.051608</td>\n",
       "      <td>-0.510787</td>\n",
       "      <td>-0.043116</td>\n",
       "      <td>0.593685</td>\n",
       "      <td>0.033465</td>\n",
       "      <td>-0.159935</td>\n",
       "      <td>-0.001556</td>\n",
       "      <td>1.427669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.982184 -0.418723  0.648704  0.777569  1.278544 -0.682070 -0.140218   \n",
       "1  1.009432 -0.445544  0.703062  0.828961  1.277971 -0.544692 -0.077958   \n",
       "2  0.964131 -0.389936  0.690117  0.866124  1.258624 -0.660620 -0.128217   \n",
       "3  0.948457 -0.382216  0.711337  0.833575  1.244138 -0.752523 -0.095578   \n",
       "4  0.910574 -0.306636  0.748167  0.808214  1.259955 -0.739075 -0.202448   \n",
       "\n",
       "         7         8         9         10        11        12        13  \\\n",
       "0 -0.352046 -0.154250 -0.430749  0.095327  0.495061  0.123365 -0.055955   \n",
       "1 -0.374260 -0.158336 -0.590008  0.082956  0.530169  0.090699 -0.133567   \n",
       "2 -0.401386 -0.151005 -0.549149  0.070321  0.506534  0.066263 -0.155309   \n",
       "3 -0.392389 -0.137476 -0.570683  0.031246  0.557270  0.073654 -0.155646   \n",
       "4 -0.436149 -0.051608 -0.510787 -0.043116  0.593685  0.033465 -0.159935   \n",
       "\n",
       "         14        15  \n",
       "0 -0.018547  1.452183  \n",
       "1 -0.039257  1.416739  \n",
       "2 -0.049878  1.412636  \n",
       "3  0.006648  1.400579  \n",
       "4 -0.001556  1.427669  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fbe5920-52f9-4895-8b92-02a6a90590aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_df = emb_df.merge(\n",
    "    research_df[['article_id', 'main_topic']].set_index('article_id'),\n",
    "    left_index = True,\n",
    "    right_index = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0d694c8-c686-400c-ab63-67c35db1fc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_cols = emb_df.drop(columns = ['main_topic']).columns.tolist()\n",
    "target_col = 'main_topic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd314423-d2c0-4651-b543-952a461f00c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "x = emb_df[ft_cols].values\n",
    "y = emb_df[target_col].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, \n",
    "    y,\n",
    "    test_size = 0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f87fc5-a687-4a6a-a9db-6480161aed88",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6604426-599b-4775-9a02-67f42e5cb736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.5 s, sys: 177 ms, total: 38.7 s\n",
      "Wall time: 38.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# GBC classifier\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "# train the model\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8e382b-f693-4d4f-85ac-5ec0fc696583",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "768d2504-5e41-4bbc-b6ea-28a4af5ef86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_eval(clf, x_test, y_test):\n",
    "    '''\n",
    "    This function will evaluate a sk-learn multi-class classification model based on its\n",
    "    x_test and y_test values\n",
    "    \n",
    "    params:\n",
    "        clf (Model) : The model you wish to evaluate the performance of\n",
    "        x_test (Array) : Result of the train test split\n",
    "        y_test (Array) : Result of the train test split\n",
    "    \n",
    "    returns:\n",
    "        This function will return the following evaluation metrics:\n",
    "            - Accuracy Score\n",
    "            - Matthews Correlation Coefficient\n",
    "            - Classification Report\n",
    "            - Confusion Matrix\n",
    "    \n",
    "    example:\n",
    "        clf_eval(\n",
    "            clf,\n",
    "            x_test,\n",
    "            y_test\n",
    "        )\n",
    "    '''\n",
    "    y_pred = clf.predict(x_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    y_pred = clf.predict(x_test)\n",
    "    x_pred = clf.predict(x_train)\n",
    "    test_acc = accuracy_score(y_test, y_pred)\n",
    "    print(\"Testing Accuracy : \", test_acc)\n",
    "    \n",
    "    print(\"MCC Score : \", matthews_corrcoef(y_true, y_pred))\n",
    "    \n",
    "    print(\"Classification Report : \")\n",
    "    print(classification_report(y_test, clf.predict(x_test)))\n",
    "    \n",
    "    print(confusion_matrix(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b159b03e-ccf6-45ad-b622-e16eea1413de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy :  0.9094827586206896\n",
      "MCC Score :  0.903356554232795\n",
      "Classification Report : \n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "       astro-ph.CO       0.00      0.00      0.00         3\n",
      "       astro-ph.EP       1.00      1.00      1.00         6\n",
      "       astro-ph.GA       0.46      1.00      0.63         6\n",
      "       astro-ph.HE       1.00      1.00      1.00         2\n",
      "       astro-ph.IM       0.33      1.00      0.50         1\n",
      "       astro-ph.SR       1.00      1.00      1.00         2\n",
      "   cond-mat.dis-nn       1.00      1.00      1.00         1\n",
      " cond-mat.mes-hall       1.00      1.00      1.00         3\n",
      " cond-mat.mtrl-sci       1.00      1.00      1.00         6\n",
      "cond-mat.quant-gas       1.00      1.00      1.00         1\n",
      "     cond-mat.soft       0.00      0.00      0.00         0\n",
      "cond-mat.stat-mech       0.75      1.00      0.86         3\n",
      "   cond-mat.str-el       1.00      0.86      0.92         7\n",
      " cond-mat.supr-con       1.00      1.00      1.00         1\n",
      "             cs.AI       1.00      1.00      1.00         5\n",
      "             cs.CC       0.00      0.00      0.00         1\n",
      "             cs.CE       1.00      1.00      1.00         1\n",
      "             cs.CG       1.00      1.00      1.00         1\n",
      "             cs.CL       0.95      1.00      0.97        56\n",
      "             cs.CR       1.00      1.00      1.00         9\n",
      "             cs.CV       1.00      1.00      1.00        39\n",
      "             cs.DB       1.00      1.00      1.00         3\n",
      "             cs.DC       1.00      1.00      1.00         5\n",
      "             cs.DM       1.00      1.00      1.00         2\n",
      "             cs.DS       1.00      1.00      1.00         2\n",
      "             cs.GR       0.00      0.00      0.00         1\n",
      "             cs.GT       0.00      0.00      0.00         1\n",
      "             cs.HC       1.00      1.00      1.00         5\n",
      "             cs.IR       1.00      1.00      1.00        10\n",
      "             cs.IT       0.80      1.00      0.89         4\n",
      "             cs.LG       0.96      0.97      0.96        89\n",
      "             cs.LO       1.00      1.00      1.00         3\n",
      "             cs.MA       0.00      0.00      0.00         2\n",
      "             cs.NE       0.86      1.00      0.92         6\n",
      "             cs.NI       1.00      1.00      1.00         4\n",
      "             cs.PL       0.00      0.00      0.00         0\n",
      "             cs.RO       1.00      0.91      0.95        11\n",
      "             cs.SD       1.00      1.00      1.00         1\n",
      "             cs.SE       1.00      1.00      1.00         3\n",
      "             cs.SI       1.00      1.00      1.00         4\n",
      "           econ.GN       0.00      0.00      0.00         1\n",
      "           eess.AS       0.50      0.50      0.50         2\n",
      "           eess.IV       1.00      1.00      1.00         9\n",
      "           eess.SP       1.00      1.00      1.00         4\n",
      "           eess.SY       1.00      1.00      1.00         7\n",
      "             gr-qc       1.00      1.00      1.00         5\n",
      "            hep-ex       1.00      1.00      1.00         1\n",
      "            hep-ph       1.00      1.00      1.00         7\n",
      "            hep-th       0.60      1.00      0.75         3\n",
      "           math-ph       1.00      1.00      1.00        13\n",
      "           math.AG       0.00      0.00      0.00         2\n",
      "           math.AP       1.00      1.00      1.00        10\n",
      "           math.CA       0.20      1.00      0.33         1\n",
      "           math.CO       1.00      1.00      1.00         8\n",
      "           math.CV       0.00      0.00      0.00         3\n",
      "           math.DS       1.00      1.00      1.00         5\n",
      "           math.FA       0.00      0.00      0.00         1\n",
      "           math.HO       1.00      1.00      1.00         1\n",
      "           math.NA       1.00      1.00      1.00         6\n",
      "           math.NT       1.00      1.00      1.00         2\n",
      "           math.OA       0.00      0.00      0.00         0\n",
      "           math.OC       1.00      1.00      1.00         5\n",
      "           math.PR       0.80      1.00      0.89         4\n",
      "           math.QA       0.00      0.00      0.00         1\n",
      "           math.ST       1.00      1.00      1.00         1\n",
      "           nlin.AO       1.00      1.00      1.00         3\n",
      "           nlin.CD       0.00      0.00      0.00         1\n",
      "           nlin.SI       0.00      0.00      0.00         1\n",
      "           nucl-ex       0.00      0.00      0.00         1\n",
      "    physics.app-ph       0.00      0.00      0.00         2\n",
      "    physics.bio-ph       0.00      0.00      0.00         1\n",
      "   physics.chem-ph       0.00      0.00      0.00         3\n",
      "   physics.comp-ph       1.00      1.00      1.00         1\n",
      "   physics.data-an       1.00      0.50      0.67         2\n",
      "   physics.flu-dyn       0.00      0.00      0.00         2\n",
      "    physics.geo-ph       0.00      0.00      0.00         0\n",
      "    physics.optics       1.00      1.00      1.00         2\n",
      "  physics.plasm-ph       1.00      1.00      1.00         2\n",
      "    physics.soc-ph       0.00      0.00      0.00         0\n",
      "          q-bio.BM       0.00      0.00      0.00         1\n",
      "          q-bio.CB       1.00      1.00      1.00         1\n",
      "          q-bio.NC       1.00      0.50      0.67         2\n",
      "          q-bio.PE       0.00      0.00      0.00         1\n",
      "          q-bio.QM       0.00      0.00      0.00         3\n",
      "          q-fin.GN       0.00      0.00      0.00         1\n",
      "          q-fin.MF       1.00      0.50      0.67         2\n",
      "          quant-ph       1.00      1.00      1.00        10\n",
      "           stat.AP       1.00      1.00      1.00         2\n",
      "           stat.CO       0.00      0.00      0.00         0\n",
      "           stat.ME       1.00      1.00      1.00         3\n",
      "           stat.ML       0.83      1.00      0.91         5\n",
      "\n",
      "          accuracy                           0.91       464\n",
      "         macro avg       0.66      0.68      0.66       464\n",
      "      weighted avg       0.89      0.91      0.90       464\n",
      "\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 6 0 ... 0 0 0]\n",
      " [0 0 6 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 3 0]\n",
      " [0 0 0 ... 0 0 5]]\n",
      "CPU times: user 288 ms, sys: 6.48 ms, total: 295 ms\n",
      "Wall time: 302 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vatsalpatel/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vatsalpatel/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vatsalpatel/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vatsalpatel/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vatsalpatel/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vatsalpatel/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf_eval(\n",
    "    clf,\n",
    "    x_test,\n",
    "    y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f438fe8b-ebbb-484d-bf34-716e4b7d9fd1",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2ccbad5-9504-48f1-a780-7c2ec6a7b5b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cs.LG'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ft = [mdl.wv.get_vector(str('21'))]\n",
    "clf.predict(pred_ft)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc1861e-d44b-48ab-abda-ddc3fc16b777",
   "metadata": {},
   "source": [
    "## Concluding Remarks\n",
    "\n",
    "\n",
    "## Resources\n",
    "- [1] https://neo4j.com/docs/graph-data-science/current/algorithms/ml-models/node-classification/#:~:text=Node%20Classification%20is%20a%20common,classification%20problems%3A%20binary%20and%20multiclass.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12205ff3-06b6-417f-9b65-52cf368f2c22",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
