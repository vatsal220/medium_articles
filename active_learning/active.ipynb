{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "256d845c-9397-4d6f-92e4-18fef599770c",
   "metadata": {},
   "source": [
    "# Active Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7f7903b-7bbe-41b6-a21b-e73ede0ab03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "import random\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b76ab33-f891-4c56-87f7-14dd3f856e1d",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "The business problem we are going to solve is associated to demographic modelling. Given some vital statistics associated to the users on our platform, we want to identify the gender associated to the user. We have a large amount of data but little to no labelled data. The goal is to build a model to identify the gender of a user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951c5f0e-e677-476a-ab59-efd7bafe9a97",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ff81d3-b8e2-4d85-a771-35fa34f2ba0e",
   "metadata": {},
   "source": [
    "In case this needs to be said, if you're using this approach to solve a problem prominent to you, don't bother generating a dataset, use the one you're working with. I'm only generating a dataset for simplicity, reproducibility and to outline a use case on how such a problem could be solved using active learning.  \n",
    "\n",
    "We are going to generate fake vital statistics associated to humans. The function we're building will randomly generate fake height, weight and age data. The resulting DataFrame from the function outlined below will yield a CSV with :   \n",
    "- uuid (UUID4) : A unique identifier to the user  \n",
    "- height (Integer) : The height of the user in cm  \n",
    "- weight (Integer) : The weight of the user in pounds (lbs)  \n",
    "- age (Integer) : The age of the user  \n",
    "- gender (String) : The gender associated to the user if known  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6428589d-7938-4efd-86b7-72d3d20bb0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n = 1000):\n",
    "    '''\n",
    "    This function will simulate the generation of gender data. It will randomly create\n",
    "    columns associated to the height (cm), weight, age and gender. The gender column\n",
    "    will not be completely filled out, it will have a few sample rows labelled to a gender.\n",
    "    \n",
    "    params:\n",
    "        n (Integer) : The number of rows you want to synthesize\n",
    "        \n",
    "    returns:\n",
    "        A dataframe with the columns of uuid, height, weight, age and gender.\n",
    "            - uuid (UUID4) : A unique identifier to the user\n",
    "            - height (Integer) : The height of the user in cm\n",
    "            - weight (Integer) : The weight of the user in pounds (lbs)\n",
    "            - age (Integer) : The age of the user\n",
    "            - gender (String) : The gender associated to the user if known\n",
    "        \n",
    "    example:\n",
    "        gender_df = generate_data(n = 1000)\n",
    "    '''\n",
    "    # we have more np.nan than Male or Female so that we can skew majority of the\n",
    "    # data to be missing\n",
    "    genders = ['Male', 'Female', np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "    height_range = (50, 200)\n",
    "    weight_range = (30, 250)\n",
    "    age_range = (3, 70)\n",
    "    \n",
    "    d = pd.DataFrame(\n",
    "        {\n",
    "            'uuid' : [uuid.uuid4() for _ in range(n)],\n",
    "            'height' : [random.randint(height_range[0], height_range[1]) for _ in range(n)],\n",
    "            'weight' : [random.randint(weight_range[0], weight_range[1]) for _ in range(n)],\n",
    "            'age' : [random.randint(age_range[0], age_range[1]) for _ in range(n)],\n",
    "            'gender' : [random.choice(genders) for _ in range(n)]\n",
    "        }\n",
    "    ).drop_duplicates()\n",
    "    d = d.set_index('uuid')\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "065c30ec-3803-463d-befe-61c453c0f674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_df = generate_data(n = 1000)\n",
    "gender_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ff96ce2-5987-477e-9cad-5d21acc406ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uuid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>e64f4c9c-1132-4a95-b0a9-6ae6d54bd43c</th>\n",
       "      <td>144</td>\n",
       "      <td>217</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667294ec-c6c6-47b8-86cd-b0987d23f19a</th>\n",
       "      <td>93</td>\n",
       "      <td>225</td>\n",
       "      <td>52</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77a163ae-05a3-4a87-96d9-b68103af541d</th>\n",
       "      <td>106</td>\n",
       "      <td>206</td>\n",
       "      <td>39</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7bdafd42-cfd5-47d1-a881-91c9f0ab6c18</th>\n",
       "      <td>142</td>\n",
       "      <td>161</td>\n",
       "      <td>58</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c348e0fc-64ff-43ba-b50d-632585073e28</th>\n",
       "      <td>68</td>\n",
       "      <td>245</td>\n",
       "      <td>68</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      height  weight  age  gender\n",
       "uuid                                                             \n",
       "e64f4c9c-1132-4a95-b0a9-6ae6d54bd43c     144     217   42     NaN\n",
       "667294ec-c6c6-47b8-86cd-b0987d23f19a      93     225   52     NaN\n",
       "77a163ae-05a3-4a87-96d9-b68103af541d     106     206   39  Female\n",
       "7bdafd42-cfd5-47d1-a881-91c9f0ab6c18     142     161   58     NaN\n",
       "c348e0fc-64ff-43ba-b50d-632585073e28      68     245   68     NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4182d15c-9f74-4b74-b549-2cf600f8346d",
   "metadata": {},
   "source": [
    "Of course, since we randomly generated data, we will have weird labelled values, like a 39 year old man who weighs 214 pounds and is 78 centimeters tall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91ba120b-8c0a-4aab-abba-05f3071d3dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>125.906000</td>\n",
       "      <td>140.664000</td>\n",
       "      <td>36.735000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43.570007</td>\n",
       "      <td>64.555329</td>\n",
       "      <td>19.603037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>88.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>126.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>163.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>53.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            height       weight          age\n",
       "count  1000.000000  1000.000000  1000.000000\n",
       "mean    125.906000   140.664000    36.735000\n",
       "std      43.570007    64.555329    19.603037\n",
       "min      50.000000    30.000000     3.000000\n",
       "25%      88.000000    84.000000    19.000000\n",
       "50%     126.000000   139.000000    38.000000\n",
       "75%     163.000000   199.000000    53.000000\n",
       "max     200.000000   250.000000    70.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f15786b-0b9b-4ff9-bd22-44824342a02f",
   "metadata": {},
   "source": [
    "## Annotate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038f443b-36e7-41c2-80ac-cf4a06050487",
   "metadata": {},
   "source": [
    "Here people would usually annotate their datasets associated to the labels, for the sake of speed and simplicity I'm going to select the randomly assigned gender data. There are various sampling stategies (like purposeful sampling and convenience sampling) you can investigate into to best select the data points to annotate. Purposeful sampling refers to selective sampling which would yield informative information to the model. Convenience sampling refers to easy to label information. Be aware, both of these methods does introduce a bias into the labelling process and could positively / negatively impact the model performance (hard to say and depends highly on the problem you're trying to solve) in comparison to random sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48c384ca-d0d8-48e7-97be-f8461ca0ec03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Female    129\n",
       "Male      122\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee4ae5d8-5982-451c-953f-b7372b998076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(251, 4) (749, 4)\n"
     ]
    }
   ],
   "source": [
    "train_df = gender_df[~gender_df['gender'].isna()].copy()\n",
    "pred_df = gender_df[gender_df['gender'].isna()].copy()\n",
    "print(train_df.shape, pred_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db92866c-d2b9-487e-a041-621a35471013",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8f8bb3-8ab0-400d-8e17-eea4b3ec89f5",
   "metadata": {},
   "source": [
    "I'm going to use the Gradient Boosting model to train the binary classifier, in a real world situation you should try many different classifiers (like SVC, Logistic Regression, KNN, XG Boost, etc.) and evaluate the performance of each. You should also conduct hyperparameter tuning on these models to optimize the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f017f4fb-8f12-444f-b76c-91d4c4ab0036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature, target breakdown\n",
    "ft_cols = train_df.drop(columns = ['gender']).columns.tolist()\n",
    "target_col = 'gender'\n",
    "\n",
    "# train test split\n",
    "x = train_df[ft_cols].values\n",
    "y = train_df[target_col].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, \n",
    "    y,\n",
    "    test_size = 0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e3920e1-cca0-4286-a218-5a0af3617311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GBC classifier\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "# train the model\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faed10e0-82df-4d0e-be2c-16a55ededf02",
   "metadata": {},
   "source": [
    "## Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c7e0ecc-8d0f-462b-8ac5-18998cc3bfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy :  0.5526315789473685\n",
      "MCC Score :  0.10277777777777777\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Female       0.57      0.57      0.57        40\n",
      "        Male       0.53      0.53      0.53        36\n",
      "\n",
      "    accuracy                           0.55        76\n",
      "   macro avg       0.55      0.55      0.55        76\n",
      "weighted avg       0.55      0.55      0.55        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def clf_eval(clf, x_test, y_test):\n",
    "    '''\n",
    "    This function will evaluate a sk-learn multi-class classification model based on its\n",
    "    x_test and y_test values\n",
    "    \n",
    "    params:\n",
    "        clf (Model) : The model you wish to evaluate the performance of\n",
    "        x_test (Array) : Result of the train test split\n",
    "        y_test (Array) : Result of the train test split\n",
    "    \n",
    "    returns:\n",
    "        This function will return the following evaluation metrics:\n",
    "            - Accuracy Score\n",
    "            - Matthews Correlation Coefficient\n",
    "            - Classification Report\n",
    "            - Confusion Matrix\n",
    "    \n",
    "    example:\n",
    "        clf_eval(\n",
    "            clf,\n",
    "            x_test,\n",
    "            y_test\n",
    "        )\n",
    "    '''\n",
    "    y_pred = clf.predict(x_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    y_pred = clf.predict(x_test)\n",
    "    test_acc = accuracy_score(y_test, y_pred)\n",
    "    print(\"Testing Accuracy : \", test_acc)\n",
    "    \n",
    "    print(\"MCC Score : \", matthews_corrcoef(y_true, y_pred))\n",
    "    \n",
    "    print(\"Classification Report : \")\n",
    "    print(classification_report(y_test, clf.predict(x_test)))\n",
    "    \n",
    "    \n",
    "clf_eval(\n",
    "    clf,\n",
    "    x_test,\n",
    "    y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036c1c61-1af0-4b0d-81e9-778a13cca4dd",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e5e56d6-f6cd-4f61-99fc-582ff14abc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['pred_proba'] = pred_df[ft_cols].apply(lambda x : dict(\n",
    "    zip(clf.classes_, clf.predict_proba(x.values[None])[0])\n",
    "), axis = 1)\n",
    "pred_df['pred'] = pred_df[ft_cols].apply(lambda x : clf.predict(x.values[None])[0], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4a38be-e8f2-4c76-a4e6-5ec4b2cd1fd4",
   "metadata": {},
   "source": [
    "## Get Annotated & To Annoate Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e16249-1874-4b3d-a954-6637b8aa822f",
   "metadata": {},
   "source": [
    "Predictions with low predicted probabilities will be annotated manually by the user, while predictions which have high predicted probability will be assumed to be a good prediction generated by the model. This will allow us to increase our labelled data and retrain a new model based on the best performing results of the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b15d2e12-b94e-47b9-8546-b6df6a55ab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# low predictions with threshold <= 0.6\n",
    "low_th= 0.6\n",
    "\n",
    "# high predictions with threshold >= 0.9\n",
    "high_th = 0.9\n",
    "\n",
    "def check_preds(pred_dct, low_th = low_th, high_th = high_th):\n",
    "    '''\n",
    "    This function will check the dictionary associated to the prediction probabilities\n",
    "    generated by the model. It will return either `annotate`, `annotated` or `neither`\n",
    "    as a result.\n",
    "    \n",
    "    params:\n",
    "        pred_dct (Dictionary) : The keys are the classes, values are the predicted proba\n",
    "        low_th (Integer) : The low prediction proba threshold\n",
    "        high_th (Integer): The high prediction proba threshold\n",
    "        \n",
    "    returns:\n",
    "        This function will return the following:\n",
    "            `annotate` : if the maximum value in the pred_dct is less than or equal to\n",
    "                         the low_th\n",
    "            `annotated` : if the maximum value in the pred_dct is greater than or equal to\n",
    "                          the high_th\n",
    "            'neither' : If it does not fall in the other two ranges\n",
    "            \n",
    "    example:\n",
    "        pred_df['annotate_decision'] = pred_df['pred_proba'].apply(check_preds)\n",
    "    '''\n",
    "    \n",
    "    max_val = max(list(pred_dct.values()))\n",
    "    if max_val <= low_th:\n",
    "        return 'annotate'\n",
    "    elif max_val >= high_th:\n",
    "        return 'annotated'\n",
    "    else:\n",
    "        return 'neither'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "993a780f-cbd5-4e74-877f-fcb4343385f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['annotate_decision'] = pred_df['pred_proba'].apply(check_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8ba008a-6fd3-4ee8-a76e-2ec29ca8b82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neither      481\n",
       "annotate     210\n",
       "annotated     58\n",
       "Name: annotate_decision, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df['annotate_decision'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c34a2e89-fca9-464c-99ab-e38973ab3ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df = pred_df[pred_df['annotate_decision'] == 'annotated'].copy()\n",
    "annotate_df = pred_df[pred_df['annotate_decision'] == 'annotate'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990e596f-2bac-4e45-98ad-e286995a5f91",
   "metadata": {},
   "source": [
    "I'm just going to randomly assign a gender out of simplicity (since this is randomly generated data), but in reality you should manually label this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80e9f577-c67c-4b44-a010-28e9ca3aa38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_choices = ['Male', 'Female', np.nan, np.nan, np.nan]\n",
    "annotate_df['gender'] = [random.choice(gender_choices) for _ in range(annotate_df.shape[0])]\n",
    "annotate_df = annotate_df[~annotate_df['gender'].isna()].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3927f9-97ee-4837-89e1-2a0fdeabfb8b",
   "metadata": {},
   "source": [
    "## Update Labelled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be52ed2f-3781-4ade-8420-ad5c62e5d967",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df['gender'] = annotated_df['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82f4bcc6-60ae-4dc5-896a-63f7e371334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df = pd.concat([annotated_df, annotate_df, train_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc574977-bc23-40c8-a7e0-6af29de96728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(396, 7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5e3d88-0337-4253-860d-928560352953",
   "metadata": {},
   "source": [
    "## Retrain Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c0ddb38-acbb-4c45-adbd-e2db94541d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature, target breakdown\n",
    "ft_cols = ['height', 'weight', 'age']\n",
    "target_col = 'gender'\n",
    "\n",
    "# train test split\n",
    "x = annotated_df[ft_cols].values\n",
    "y = annotated_df[target_col].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, \n",
    "    y,\n",
    "    test_size = 0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e098dfd-ceb1-468b-8f08-91c95025e50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GBC classifier\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "# train the model\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c2cf05-744c-495e-a049-daf06bdcdc10",
   "metadata": {},
   "source": [
    "## Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecda2526-0db6-48e3-9a6b-0b520925c19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy :  0.5294117647058824\n",
      "MCC Score :  0.06628740703572837\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Female       0.58      0.49      0.53        65\n",
      "        Male       0.48      0.57      0.53        54\n",
      "\n",
      "    accuracy                           0.53       119\n",
      "   macro avg       0.53      0.53      0.53       119\n",
      "weighted avg       0.54      0.53      0.53       119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_eval(\n",
    "    clf,\n",
    "    x_test,\n",
    "    y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38b95cb-3626-4b4f-a1c0-044e6d25c872",
   "metadata": {},
   "source": [
    "## Caveats\n",
    "\n",
    "Be aware that this example above was associated to randomly generated data, this example was to show the power of active learning and how to use it to solve problems when there are a limited amount of labelled data. Although the performance of the model improved, the model is essentially learning randomness so do take these results with a grain of salt. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183fc07d-afeb-48bc-9d0d-1eebfba87d05",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
