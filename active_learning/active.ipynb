{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "256d845c-9397-4d6f-92e4-18fef599770c",
   "metadata": {},
   "source": [
    "# Active Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7f7903b-7bbe-41b6-a21b-e73ede0ab03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import uuid\n",
    "import random\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b76ab33-f891-4c56-87f7-14dd3f856e1d",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "The business problem we are going to solve is associated to demographic modelling. Given some vital statistics associated to the users on our platform, we want to identify the gender associated to the user. We have a large amount of data but little to no labelled data. The goal is to build a model to identify the gender of a user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951c5f0e-e677-476a-ab59-efd7bafe9a97",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ff81d3-b8e2-4d85-a771-35fa34f2ba0e",
   "metadata": {},
   "source": [
    "In case this needs to be said, if you're using this approach to solve a problem prominent to you, don't bother generating a dataset, use the one you're working with. I'm only generating a dataset for simplicity, reproducibility and to outline a use case on how such a problem could be solved using active learning.  \n",
    "\n",
    "We are going to generate fake vital statistics associated to humans. The function we're building will randomly generate fake height, weight and age data. The resulting DataFrame from the function outlined below will yield a CSV with :   \n",
    "- uuid (UUID4) : A unique identifier to the user  \n",
    "- height (Integer) : The height of the user in cm  \n",
    "- weight (Integer) : The weight of the user in pounds (lbs)  \n",
    "- age (Integer) : The age of the user  \n",
    "- gender (String) : The gender associated to the user if known  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6428589d-7938-4efd-86b7-72d3d20bb0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n = 1000):\n",
    "    '''\n",
    "    This function will simulate the generation of gender data. It will randomly create\n",
    "    columns associated to the height (cm), weight, age and gender. The gender column\n",
    "    will not be completely filled out, it will have a few sample rows labelled to a gender.\n",
    "    \n",
    "    params:\n",
    "        n (Integer) : The number of rows you want to synthesize\n",
    "        \n",
    "    returns:\n",
    "        A dataframe with the columns of uuid, height, weight, age and gender.\n",
    "            - uuid (UUID4) : A unique identifier to the user\n",
    "            - height (Integer) : The height of the user in cm\n",
    "            - weight (Integer) : The weight of the user in pounds (lbs)\n",
    "            - age (Integer) : The age of the user\n",
    "            - gender (String) : The gender associated to the user if known\n",
    "        \n",
    "    example:\n",
    "        gender_df = generate_data(n = 1000)\n",
    "    '''\n",
    "    # we have more np.nan than Male or Female so that we can skew majority of the\n",
    "    # data to be missing\n",
    "    genders = ['Male', 'Female', np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "    height_range = (50, 200)\n",
    "    weight_range = (30, 250)\n",
    "    age_range = (3, 70)\n",
    "    \n",
    "    d = pd.DataFrame(\n",
    "        {\n",
    "            'uuid' : [uuid.uuid4() for _ in range(n)],\n",
    "            'height' : [random.randint(height_range[0], height_range[1]) for _ in range(n)],\n",
    "            'weight' : [random.randint(weight_range[0], weight_range[1]) for _ in range(n)],\n",
    "            'age' : [random.randint(age_range[0], age_range[1]) for _ in range(n)],\n",
    "            'gender' : [random.choice(genders) for _ in range(n)]\n",
    "        }\n",
    "    ).drop_duplicates()\n",
    "    d = d.set_index('uuid')\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "065c30ec-3803-463d-befe-61c453c0f674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_df = generate_data(n = 1000)\n",
    "gender_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ff96ce2-5987-477e-9cad-5d21acc406ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uuid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c7f7bb27-5233-46f3-a699-da4c8fa8987b</th>\n",
       "      <td>133</td>\n",
       "      <td>118</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43e56764-cf8a-420a-a35c-f91a71282da3</th>\n",
       "      <td>162</td>\n",
       "      <td>77</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6e3f9de8-3de7-4e39-8969-344d500ff2f1</th>\n",
       "      <td>81</td>\n",
       "      <td>153</td>\n",
       "      <td>11</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b7758055-9b18-4be5-b073-fe33b997bae9</th>\n",
       "      <td>186</td>\n",
       "      <td>105</td>\n",
       "      <td>24</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a4283816-7538-4411-94ad-44429d0471bb</th>\n",
       "      <td>127</td>\n",
       "      <td>247</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      height  weight  age  gender\n",
       "uuid                                                             \n",
       "c7f7bb27-5233-46f3-a699-da4c8fa8987b     133     118    5     NaN\n",
       "43e56764-cf8a-420a-a35c-f91a71282da3     162      77   13     NaN\n",
       "6e3f9de8-3de7-4e39-8969-344d500ff2f1      81     153   11  Female\n",
       "b7758055-9b18-4be5-b073-fe33b997bae9     186     105   24    Male\n",
       "a4283816-7538-4411-94ad-44429d0471bb     127     247   39     NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4182d15c-9f74-4b74-b549-2cf600f8346d",
   "metadata": {},
   "source": [
    "Of course, since we randomly generated data, we will have weird labelled values, like a 11 year old girl who weighs 153 pounds and is 81 centimeters tall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91ba120b-8c0a-4aab-abba-05f3071d3dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>126.93600</td>\n",
       "      <td>141.352000</td>\n",
       "      <td>37.28200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43.79829</td>\n",
       "      <td>64.175935</td>\n",
       "      <td>19.44764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>50.00000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>88.00000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>21.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>129.00000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>37.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>166.00000</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>54.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>200.00000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>70.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           height       weight         age\n",
       "count  1000.00000  1000.000000  1000.00000\n",
       "mean    126.93600   141.352000    37.28200\n",
       "std      43.79829    64.175935    19.44764\n",
       "min      50.00000    30.000000     3.00000\n",
       "25%      88.00000    87.000000    21.00000\n",
       "50%     129.00000   145.000000    37.00000\n",
       "75%     166.00000   197.000000    54.00000\n",
       "max     200.00000   250.000000    70.00000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f15786b-0b9b-4ff9-bd22-44824342a02f",
   "metadata": {},
   "source": [
    "## Annotate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038f443b-36e7-41c2-80ac-cf4a06050487",
   "metadata": {},
   "source": [
    "Here people would usually annotate their datasets associated to the labels, for the sake of speed and simplicity I'm going to select the randomly assigned gender data. There are various sampling stategies (like purposeful sampling and convenience sampling) you can investigate into to best select the data points to annotate. Purposeful sampling refers to selective sampling which would yield informative information to the model. Convenience sampling refers to easy to label information. Be aware, both of these methods does introduce a bias into the labelling process and could positively / negatively impact the model performance (hard to say and depends highly on the problem you're trying to solve) in comparison to random sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48c384ca-d0d8-48e7-97be-f8461ca0ec03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male      128\n",
       "Female    104\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee4ae5d8-5982-451c-953f-b7372b998076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(232, 4) (768, 4)\n"
     ]
    }
   ],
   "source": [
    "train_df = gender_df[~gender_df['gender'].isna()].copy()\n",
    "pred_df = gender_df[gender_df['gender'].isna()].copy()\n",
    "print(train_df.shape, pred_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db92866c-d2b9-487e-a041-621a35471013",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8f8bb3-8ab0-400d-8e17-eea4b3ec89f5",
   "metadata": {},
   "source": [
    "I'm going to use the Gradient Boosting model to train the binary classifier, in a real world situation you should try many different classifiers (like SVC, Logistic Regression, KNN, XG Boost, etc.) and evaluate the performance of each. You should also conduct hyperparameter tuning on these models to optimize the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f017f4fb-8f12-444f-b76c-91d4c4ab0036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature, target breakdown\n",
    "ft_cols = train_df.drop(columns = ['gender']).columns.tolist()\n",
    "target_col = 'gender'\n",
    "\n",
    "# train test split\n",
    "x = train_df[ft_cols].values\n",
    "y = train_df[target_col].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, \n",
    "    y,\n",
    "    test_size = 0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e3920e1-cca0-4286-a218-5a0af3617311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GBC classifier\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "# train the model\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faed10e0-82df-4d0e-be2c-16a55ededf02",
   "metadata": {},
   "source": [
    "## Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c7e0ecc-8d0f-462b-8ac5-18998cc3bfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy :  0.5\n",
      "MCC Score :  0.004973585797187662\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Female       0.42      0.52      0.46        29\n",
      "        Male       0.59      0.49      0.53        41\n",
      "\n",
      "    accuracy                           0.50        70\n",
      "   macro avg       0.50      0.50      0.50        70\n",
      "weighted avg       0.52      0.50      0.50        70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def clf_eval(clf, x_test, y_test):\n",
    "    '''\n",
    "    This function will evaluate a sk-learn multi-class classification model based on its\n",
    "    x_test and y_test values\n",
    "    \n",
    "    params:\n",
    "        clf (Model) : The model you wish to evaluate the performance of\n",
    "        x_test (Array) : Result of the train test split\n",
    "        y_test (Array) : Result of the train test split\n",
    "    \n",
    "    returns:\n",
    "        This function will return the following evaluation metrics:\n",
    "            - Accuracy Score\n",
    "            - Matthews Correlation Coefficient\n",
    "            - Classification Report\n",
    "            - Confusion Matrix\n",
    "    \n",
    "    example:\n",
    "        clf_eval(\n",
    "            clf,\n",
    "            x_test,\n",
    "            y_test\n",
    "        )\n",
    "    '''\n",
    "    y_pred = clf.predict(x_test)\n",
    "    y_true = y_test\n",
    "    \n",
    "    y_pred = clf.predict(x_test)\n",
    "    test_acc = accuracy_score(y_test, y_pred)\n",
    "    print(\"Testing Accuracy : \", test_acc)\n",
    "    \n",
    "    print(\"MCC Score : \", matthews_corrcoef(y_true, y_pred))\n",
    "    \n",
    "    print(\"Classification Report : \")\n",
    "    print(classification_report(y_test, clf.predict(x_test)))\n",
    "    \n",
    "    \n",
    "clf_eval(\n",
    "    clf,\n",
    "    x_test,\n",
    "    y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036c1c61-1af0-4b0d-81e9-778a13cca4dd",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e5e56d6-f6cd-4f61-99fc-582ff14abc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['pred_proba'] = pred_df[ft_cols].apply(lambda x : dict(\n",
    "    zip(clf.classes_, clf.predict_proba(x.values[None])[0])\n",
    "), axis = 1)\n",
    "pred_df['pred'] = pred_df[ft_cols].apply(lambda x : clf.predict(x.values[None])[0], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4a38be-e8f2-4c76-a4e6-5ec4b2cd1fd4",
   "metadata": {},
   "source": [
    "## Get Annotated & To Annoate Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e16249-1874-4b3d-a954-6637b8aa822f",
   "metadata": {},
   "source": [
    "Predictions with low predicted probabilities will be annotated manually by the user, while predictions which have high predicted probability will be assumed to be a good prediction generated by the model. This will allow us to increase our labelled data and retrain a new model based on the best performing results of the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b15d2e12-b94e-47b9-8546-b6df6a55ab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# low predictions with threshold <= 0.6\n",
    "low_th = 0.6\n",
    "\n",
    "# high predictions with threshold >= 0.9\n",
    "high_th = 0.9\n",
    "\n",
    "def check_preds(pred_dct, low_th = low_th, high_th = high_th):\n",
    "    '''\n",
    "    This function will check the dictionary associated to the prediction probabilities\n",
    "    generated by the model. It will return either `annotate`, `annotated` or `neither`\n",
    "    as a result.\n",
    "    \n",
    "    params:\n",
    "        pred_dct (Dictionary) : The keys are the classes, values are the predicted proba\n",
    "        low_th (Integer) : The low prediction proba threshold\n",
    "        high_th (Integer): The high prediction proba threshold\n",
    "        \n",
    "    returns:\n",
    "        This function will return the following:\n",
    "            `annotate` : if the maximum value in the pred_dct is less than or equal to\n",
    "                         the low_th\n",
    "            `annotated` : if the maximum value in the pred_dct is greater than or equal to\n",
    "                          the high_th\n",
    "            'neither' : If it does not fall in the other two ranges\n",
    "            \n",
    "    example:\n",
    "        pred_df['annotate_decision'] = pred_df['pred_proba'].apply(check_preds)\n",
    "    '''\n",
    "    \n",
    "    max_val = max(list(pred_dct.values()))\n",
    "    if max_val <= low_th:\n",
    "        return 'annotate'\n",
    "    elif max_val >= high_th:\n",
    "        return 'annotated'\n",
    "    else:\n",
    "        return 'neither'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "993a780f-cbd5-4e74-877f-fcb4343385f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['annotate_decision'] = pred_df['pred_proba'].apply(check_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8ba008a-6fd3-4ee8-a76e-2ec29ca8b82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neither      504\n",
       "annotate     144\n",
       "annotated    120\n",
       "Name: annotate_decision, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df['annotate_decision'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c34a2e89-fca9-464c-99ab-e38973ab3ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df = pred_df[pred_df['annotate_decision'] == 'annotated'].copy()\n",
    "annotate_df = pred_df[pred_df['annotate_decision'] == 'annotate'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990e596f-2bac-4e45-98ad-e286995a5f91",
   "metadata": {},
   "source": [
    "I'm just going to randomly assign a gender out of simplicity (since this is randomly generated data), but in reality you should manually label this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80e9f577-c67c-4b44-a010-28e9ca3aa38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_choices = ['Male', 'Female', np.nan, np.nan, np.nan]\n",
    "annotate_df['gender'] = [random.choice(gender_choices) for _ in range(annotate_df.shape[0])]\n",
    "annotate_df = annotate_df[~annotate_df['gender'].isna()].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3927f9-97ee-4837-89e1-2a0fdeabfb8b",
   "metadata": {},
   "source": [
    "## Update Labelled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be52ed2f-3781-4ade-8420-ad5c62e5d967",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df['gender'] = annotated_df['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82f4bcc6-60ae-4dc5-896a-63f7e371334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df = pd.concat([annotated_df, annotate_df, train_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc574977-bc23-40c8-a7e0-6af29de96728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401, 7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5e3d88-0337-4253-860d-928560352953",
   "metadata": {},
   "source": [
    "## Retrain Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c0ddb38-acbb-4c45-adbd-e2db94541d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature, target breakdown\n",
    "ft_cols = ['height', 'weight', 'age']\n",
    "target_col = 'gender'\n",
    "\n",
    "# train test split\n",
    "x = annotated_df[ft_cols].values\n",
    "y = annotated_df[target_col].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, \n",
    "    y,\n",
    "    test_size = 0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e098dfd-ceb1-468b-8f08-91c95025e50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GBC classifier\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "# train the model\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c2cf05-744c-495e-a049-daf06bdcdc10",
   "metadata": {},
   "source": [
    "## Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecda2526-0db6-48e3-9a6b-0b520925c19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy :  0.7520661157024794\n",
      "MCC Score :  0.5242538184376094\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Female       0.85      0.68      0.76        69\n",
      "        Male       0.67      0.85      0.75        52\n",
      "\n",
      "    accuracy                           0.75       121\n",
      "   macro avg       0.76      0.76      0.75       121\n",
      "weighted avg       0.77      0.75      0.75       121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_eval(\n",
    "    clf,\n",
    "    x_test,\n",
    "    y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38b95cb-3626-4b4f-a1c0-044e6d25c872",
   "metadata": {},
   "source": [
    "## Caveats\n",
    "\n",
    "Be aware that this example above was associated to randomly generated data, this example was to show the power of active learning and how to use it to solve problems when there are a limited amount of labelled data. Although the performance of the model improved, the model is essentially learning randomness so do take these results with a grain of salt. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183fc07d-afeb-48bc-9d0d-1eebfba87d05",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
