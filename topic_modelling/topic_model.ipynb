{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8644bf09-042c-4b56-b4ba-9de0edb79459",
   "metadata": {},
   "source": [
    "# Supervised & Unsupervised Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6af3e56d-77d1-40ac-bdcc-538c21abf43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import string\n",
    "import unidecode\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import List\n",
    "\n",
    "try:\n",
    "    from nltk.corpus import stopwords\n",
    "except:\n",
    "    import nltk\n",
    "    nltk.download('stopwords')\n",
    "finally:\n",
    "    from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e875103-ec29-4165-984e-ce2c4abb133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "queries = [\n",
    "    'automl', 'machinelearning', 'data', 'phyiscs','mathematics', 'recommendation system', 'nlp', 'neural networks'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afca02b4-3cc9-4bc5-9f1f-4c5a9e1e0166",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71fbc053-3bd7-4747-924b-7ce384ea417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_arxiv(queries: List[str], max_results: int = 100) -> pd.DataFrame:\n",
    "    '''\n",
    "    This function will search arxiv associated to a set of queries and store\n",
    "    the latest 10000 (max_results) associated to that search.\n",
    "    \n",
    "    params:\n",
    "        queries (List -> Str) : A list of strings containing keywords you want\n",
    "                                to search on Arxiv\n",
    "        max_results (Int) : The maximum number of results you want to see associated\n",
    "                            to your search. Default value is 1000, capped at 300000\n",
    "                            \n",
    "    returns:\n",
    "        This function will return a DataFrame holding the following columns associated\n",
    "        to the queries the user has passed. \n",
    "            `title`, `date`, `article_id`, `url`, `main_topic`, `all_topics`\n",
    "    \n",
    "    example:\n",
    "        research_df = search_arxiv(\n",
    "            queries = ['automl', 'recommender system', 'nlp', 'data science'],\n",
    "            max_results = 10000\n",
    "        )\n",
    "    '''\n",
    "    d = []\n",
    "    searches = []\n",
    "    # hitting the API\n",
    "    for query in queries:\n",
    "        search = arxiv.Search(\n",
    "          query = query,\n",
    "          max_results = max_results,\n",
    "          sort_by = arxiv.SortCriterion.SubmittedDate,\n",
    "          sort_order = arxiv.SortOrder.Descending\n",
    "        )\n",
    "        searches.append(search)\n",
    "    \n",
    "    # Converting search result into df\n",
    "    for search in searches:\n",
    "        for res in search.results():\n",
    "            data = {\n",
    "                'title' : res.title,\n",
    "                'date' : res.published,\n",
    "                'article_id' : res.entry_id,\n",
    "                'url' : res.pdf_url,\n",
    "                'main_topic' : res.primary_category,\n",
    "                'summary' : res.summary,\n",
    "                'all_topics' : res.categories,\n",
    "                'authors' : res.authors\n",
    "            }\n",
    "            d.append(data)\n",
    "        \n",
    "    d = pd.DataFrame(d)\n",
    "    d['year'] = pd.DatetimeIndex(d['date']).year\n",
    "    \n",
    "    # change article id from url to integer\n",
    "    unique_article_ids = d.article_id.unique()\n",
    "    article_mapping = {art:idx for idx,art in enumerate(unique_article_ids)}\n",
    "    d['article_id'] = d['article_id'].map(article_mapping)\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0f6b598-b93d-405a-8d44-f8c02cde8ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(647, 9)\n"
     ]
    }
   ],
   "source": [
    "# fetch data from arXiv\n",
    "research_df = search_arxiv(\n",
    "    queries = queries,\n",
    "    max_results = 100\n",
    ")\n",
    "print(research_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "238f0c53-f268-44f5-be58-81b9017f1396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>article_id</th>\n",
       "      <th>url</th>\n",
       "      <th>main_topic</th>\n",
       "      <th>summary</th>\n",
       "      <th>all_topics</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multi-objective Tree-structured Parzen Estimat...</td>\n",
       "      <td>2022-12-13 17:33:02+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>http://arxiv.org/pdf/2212.06751v1</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>Hyperparameter optimization (HPO) is essential...</td>\n",
       "      <td>[cs.LG, cs.AI]</td>\n",
       "      <td>[Shuhei Watanabe, Noow Awad, Masaki Onishi, Fr...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POPNASv3: a Pareto-Optimal Neural Architecture...</td>\n",
       "      <td>2022-12-13 17:14:14+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>http://arxiv.org/pdf/2212.06735v1</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>The automated machine learning (AutoML) field ...</td>\n",
       "      <td>[cs.LG, cs.AI, cs.CV, cs.NE]</td>\n",
       "      <td>[Andrea Falanti, Eugenio Lomurno, Danilo Ardag...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AutoPINN: When AutoML Meets Physics-Informed N...</td>\n",
       "      <td>2022-12-08 03:44:08+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>http://arxiv.org/pdf/2212.04058v1</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>Physics-Informed Neural Networks (PINNs) have ...</td>\n",
       "      <td>[cs.LG, cs.AI]</td>\n",
       "      <td>[Xinle Wu, Dalin Zhang, Miao Zhang, Chenjuan G...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benchmarking AutoML algorithms on a collection...</td>\n",
       "      <td>2022-12-06 01:53:50+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>http://arxiv.org/pdf/2212.02704v2</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>Automated machine learning (AutoML) algorithms...</td>\n",
       "      <td>[cs.LG]</td>\n",
       "      <td>[Pedro Henrique Ribeiro, Patryk Orzechowski, J...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NAS-LID: Efficient Neural Architecture Search ...</td>\n",
       "      <td>2022-11-23 08:08:17+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>http://arxiv.org/pdf/2211.12759v2</td>\n",
       "      <td>cs.CV</td>\n",
       "      <td>One-shot neural architecture search (NAS) subs...</td>\n",
       "      <td>[cs.CV, cs.AI, cs.LG]</td>\n",
       "      <td>[Xin He, Jiangchao Yao, Yuxin Wang, Zhenheng T...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Multi-objective Tree-structured Parzen Estimat...   \n",
       "1  POPNASv3: a Pareto-Optimal Neural Architecture...   \n",
       "2  AutoPINN: When AutoML Meets Physics-Informed N...   \n",
       "3  Benchmarking AutoML algorithms on a collection...   \n",
       "4  NAS-LID: Efficient Neural Architecture Search ...   \n",
       "\n",
       "                       date  article_id                                url  \\\n",
       "0 2022-12-13 17:33:02+00:00           0  http://arxiv.org/pdf/2212.06751v1   \n",
       "1 2022-12-13 17:14:14+00:00           1  http://arxiv.org/pdf/2212.06735v1   \n",
       "2 2022-12-08 03:44:08+00:00           2  http://arxiv.org/pdf/2212.04058v1   \n",
       "3 2022-12-06 01:53:50+00:00           3  http://arxiv.org/pdf/2212.02704v2   \n",
       "4 2022-11-23 08:08:17+00:00           4  http://arxiv.org/pdf/2211.12759v2   \n",
       "\n",
       "  main_topic                                            summary  \\\n",
       "0      cs.LG  Hyperparameter optimization (HPO) is essential...   \n",
       "1      cs.LG  The automated machine learning (AutoML) field ...   \n",
       "2      cs.LG  Physics-Informed Neural Networks (PINNs) have ...   \n",
       "3      cs.LG  Automated machine learning (AutoML) algorithms...   \n",
       "4      cs.CV  One-shot neural architecture search (NAS) subs...   \n",
       "\n",
       "                     all_topics  \\\n",
       "0                [cs.LG, cs.AI]   \n",
       "1  [cs.LG, cs.AI, cs.CV, cs.NE]   \n",
       "2                [cs.LG, cs.AI]   \n",
       "3                       [cs.LG]   \n",
       "4         [cs.CV, cs.AI, cs.LG]   \n",
       "\n",
       "                                             authors  year  \n",
       "0  [Shuhei Watanabe, Noow Awad, Masaki Onishi, Fr...  2022  \n",
       "1  [Andrea Falanti, Eugenio Lomurno, Danilo Ardag...  2022  \n",
       "2  [Xinle Wu, Dalin Zhang, Miao Zhang, Chenjuan G...  2022  \n",
       "3  [Pedro Henrique Ribeiro, Patryk Orzechowski, J...  2022  \n",
       "4  [Xin He, Jiangchao Yao, Yuxin Wang, Zhenheng T...  2022  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f41b0a-4de7-46c3-88f3-a62d24c4a539",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95118db5-8358-46db-ad38-90a67f6550a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text: str, sw: List[str] = stopwords) -> str:\n",
    "    '''\n",
    "    This function will remove stopwords from the text\n",
    "    \n",
    "    Args:\n",
    "        text: String of data you want to remove stopwords from\n",
    "        sw: List of strings indicating the list of stopwords\n",
    "        \n",
    "    Returns:\n",
    "        The input string with the stopwords removed.\n",
    "    '''\n",
    "    return ' '.join([word for word in text.split() if word not in stopwords.words('english')])\n",
    "    \n",
    "def remove_punctuation(text: str, punct: str = string.punctuation) -> str:\n",
    "    '''\n",
    "    This function will remove punctuations from the text.\n",
    "    \n",
    "    Args:\n",
    "        text: String of data you want to remove punctuations from\n",
    "        punct: String of punctuations\n",
    "    \n",
    "    Returns:\n",
    "        The input string with the punctuations removed.\n",
    "    '''\n",
    "    cleaned_text = ''.join([char for char in text if char not in punct])\n",
    "    return cleaned_text\n",
    "    \n",
    "def unicode(text: str) -> str:\n",
    "    '''\n",
    "    This function will make all the data unicoded. Meaning Â -> A\n",
    "    \n",
    "    Args:\n",
    "        text: String of data you want to unicode\n",
    "    \n",
    "    Returns:\n",
    "        The input string unicoded.\n",
    "    '''\n",
    "    return unidecode.unidecode(text)\n",
    "    \n",
    "def clean(text: str) -> str:\n",
    "    '''\n",
    "    This method will clean the input text through unidecoding and stopword and punctuation \n",
    "    removal.\n",
    "    \n",
    "    Args:\n",
    "        text: String indicating the body of text you want to clean\n",
    "    \n",
    "    Returns:\n",
    "        A string corresponding to the cleaned version of the input string.\n",
    "    '''\n",
    "    text = unicode(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "717eb255-71c3-4287-9175-ea652410148d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.88 s, sys: 772 ms, total: 4.65 s\n",
      "Wall time: 4.66 s\n"
     ]
    }
   ],
   "source": [
    "%time research_df['cleaned_summary'] = research_df['summary'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a47deda2-19b0-493a-afd5-8d5824149863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>article_id</th>\n",
       "      <th>url</th>\n",
       "      <th>main_topic</th>\n",
       "      <th>summary</th>\n",
       "      <th>all_topics</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>cleaned_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multi-objective Tree-structured Parzen Estimat...</td>\n",
       "      <td>2022-12-13 17:33:02+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>http://arxiv.org/pdf/2212.06751v1</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>Hyperparameter optimization (HPO) is essential...</td>\n",
       "      <td>[cs.LG, cs.AI]</td>\n",
       "      <td>[Shuhei Watanabe, Noow Awad, Masaki Onishi, Fr...</td>\n",
       "      <td>2022</td>\n",
       "      <td>hyperparameter optimization hpo essential bett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POPNASv3: a Pareto-Optimal Neural Architecture...</td>\n",
       "      <td>2022-12-13 17:14:14+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>http://arxiv.org/pdf/2212.06735v1</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>The automated machine learning (AutoML) field ...</td>\n",
       "      <td>[cs.LG, cs.AI, cs.CV, cs.NE]</td>\n",
       "      <td>[Andrea Falanti, Eugenio Lomurno, Danilo Ardag...</td>\n",
       "      <td>2022</td>\n",
       "      <td>the automated machine learning automl field be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AutoPINN: When AutoML Meets Physics-Informed N...</td>\n",
       "      <td>2022-12-08 03:44:08+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>http://arxiv.org/pdf/2212.04058v1</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>Physics-Informed Neural Networks (PINNs) have ...</td>\n",
       "      <td>[cs.LG, cs.AI]</td>\n",
       "      <td>[Xinle Wu, Dalin Zhang, Miao Zhang, Chenjuan G...</td>\n",
       "      <td>2022</td>\n",
       "      <td>physicsinformed neural networks pinns recently...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benchmarking AutoML algorithms on a collection...</td>\n",
       "      <td>2022-12-06 01:53:50+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>http://arxiv.org/pdf/2212.02704v2</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>Automated machine learning (AutoML) algorithms...</td>\n",
       "      <td>[cs.LG]</td>\n",
       "      <td>[Pedro Henrique Ribeiro, Patryk Orzechowski, J...</td>\n",
       "      <td>2022</td>\n",
       "      <td>automated machine learning automl algorithms g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NAS-LID: Efficient Neural Architecture Search ...</td>\n",
       "      <td>2022-11-23 08:08:17+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>http://arxiv.org/pdf/2211.12759v2</td>\n",
       "      <td>cs.CV</td>\n",
       "      <td>One-shot neural architecture search (NAS) subs...</td>\n",
       "      <td>[cs.CV, cs.AI, cs.LG]</td>\n",
       "      <td>[Xin He, Jiangchao Yao, Yuxin Wang, Zhenheng T...</td>\n",
       "      <td>2022</td>\n",
       "      <td>oneshot neural architecture search nas substan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Multi-objective Tree-structured Parzen Estimat...   \n",
       "1  POPNASv3: a Pareto-Optimal Neural Architecture...   \n",
       "2  AutoPINN: When AutoML Meets Physics-Informed N...   \n",
       "3  Benchmarking AutoML algorithms on a collection...   \n",
       "4  NAS-LID: Efficient Neural Architecture Search ...   \n",
       "\n",
       "                       date  article_id                                url  \\\n",
       "0 2022-12-13 17:33:02+00:00           0  http://arxiv.org/pdf/2212.06751v1   \n",
       "1 2022-12-13 17:14:14+00:00           1  http://arxiv.org/pdf/2212.06735v1   \n",
       "2 2022-12-08 03:44:08+00:00           2  http://arxiv.org/pdf/2212.04058v1   \n",
       "3 2022-12-06 01:53:50+00:00           3  http://arxiv.org/pdf/2212.02704v2   \n",
       "4 2022-11-23 08:08:17+00:00           4  http://arxiv.org/pdf/2211.12759v2   \n",
       "\n",
       "  main_topic                                            summary  \\\n",
       "0      cs.LG  Hyperparameter optimization (HPO) is essential...   \n",
       "1      cs.LG  The automated machine learning (AutoML) field ...   \n",
       "2      cs.LG  Physics-Informed Neural Networks (PINNs) have ...   \n",
       "3      cs.LG  Automated machine learning (AutoML) algorithms...   \n",
       "4      cs.CV  One-shot neural architecture search (NAS) subs...   \n",
       "\n",
       "                     all_topics  \\\n",
       "0                [cs.LG, cs.AI]   \n",
       "1  [cs.LG, cs.AI, cs.CV, cs.NE]   \n",
       "2                [cs.LG, cs.AI]   \n",
       "3                       [cs.LG]   \n",
       "4         [cs.CV, cs.AI, cs.LG]   \n",
       "\n",
       "                                             authors  year  \\\n",
       "0  [Shuhei Watanabe, Noow Awad, Masaki Onishi, Fr...  2022   \n",
       "1  [Andrea Falanti, Eugenio Lomurno, Danilo Ardag...  2022   \n",
       "2  [Xinle Wu, Dalin Zhang, Miao Zhang, Chenjuan G...  2022   \n",
       "3  [Pedro Henrique Ribeiro, Patryk Orzechowski, J...  2022   \n",
       "4  [Xin He, Jiangchao Yao, Yuxin Wang, Zhenheng T...  2022   \n",
       "\n",
       "                                     cleaned_summary  \n",
       "0  hyperparameter optimization hpo essential bett...  \n",
       "1  the automated machine learning automl field be...  \n",
       "2  physicsinformed neural networks pinns recently...  \n",
       "3  automated machine learning automl algorithms g...  \n",
       "4  oneshot neural architecture search nas substan...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffad1e0-9a4d-49b1-b4bb-6c3cf9a64d0e",
   "metadata": {},
   "source": [
    "# Unsupervised Learning - LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37bdbc25-6cc5-4acb-9f4d-125e0c805c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from gensim import models, corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ae6004d-a466-4409-83b4-d00522bec283",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_summaries = research_df['cleaned_summary'].values\n",
    "article_summaries = [[word for word in nltk.word_tokenize(article)] for article in article_summaries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "050c6c29-7816-4899-9c17-bff976c525d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of all the words in the dataset\n",
    "dictionary = corpora.Dictionary(article_summaries)\n",
    "\n",
    "# Create a corpus\n",
    "corpus = [dictionary.doc2bow(article) for article in article_summaries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f01a879-54ba-4141-88ab-1c97c6d261e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.69 s, sys: 45.2 ms, total: 4.74 s\n",
      "Wall time: 4.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create an LDA model\n",
    "lda = models.LdaModel(corpus, num_topics=10, id2word=dictionary, passes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f41f910-8aba-4813-9223-55ecfdd6fef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 1: [(6, 0.54790044), (8, 0.44401333)]\n",
      "Article 2: [(4, 0.26697603), (6, 0.65080774), (7, 0.07738426)]\n",
      "Article 3: [(0, 0.4645687), (6, 0.39220694), (7, 0.13915145)]\n",
      "Article 4: [(6, 0.9916613)]\n",
      "Article 5: [(4, 0.87794346), (6, 0.11565114)]\n",
      "Article 6: [(6, 0.39041102), (7, 0.6014999)]\n",
      "Article 7: [(0, 0.5545885), (1, 0.035100326), (6, 0.40523368)]\n",
      "Article 8: [(0, 0.15213814), (6, 0.8432332)]\n",
      "Article 9: [(0, 0.3477852), (6, 0.64428633)]\n",
      "Article 10: [(6, 0.42433938), (7, 0.56949884)]\n",
      "[(0, '0.013*\"data\" + 0.010*\"the\" + 0.008*\"model\" + 0.008*\"we\" + 0.007*\"in\" + 0.005*\"systems\" + 0.004*\"results\" + 0.004*\"two\" + 0.004*\"using\" + 0.004*\"models\"'), (1, '0.010*\"data\" + 0.006*\"we\" + 0.006*\"work\" + 0.005*\"time\" + 0.005*\"in\" + 0.005*\"the\" + 0.005*\"results\" + 0.004*\"analysis\" + 0.004*\"users\" + 0.004*\"business\"'), (2, '0.010*\"we\" + 0.009*\"systems\" + 0.006*\"transmission\" + 0.006*\"the\" + 0.004*\"networks\" + 0.004*\"study\" + 0.003*\"neural\" + 0.003*\"data\" + 0.003*\"coherent\" + 0.003*\"system\"'), (3, '0.007*\"we\" + 0.007*\"the\" + 0.006*\"models\" + 0.005*\"this\" + 0.005*\"model\" + 0.004*\"in\" + 0.004*\"energy\" + 0.004*\"states\" + 0.003*\"quantum\" + 0.003*\"motion\"'), (4, '0.012*\"models\" + 0.010*\"model\" + 0.008*\"data\" + 0.008*\"we\" + 0.007*\"language\" + 0.007*\"performance\" + 0.007*\"tasks\" + 0.006*\"method\" + 0.006*\"the\" + 0.005*\"methods\"'), (5, '0.014*\"we\" + 0.008*\"the\" + 0.007*\"quantum\" + 0.006*\"in\" + 0.005*\"model\" + 0.005*\"system\" + 0.004*\"study\" + 0.004*\"time\" + 0.004*\"systems\" + 0.004*\"show\"'), (6, '0.013*\"automl\" + 0.011*\"learning\" + 0.009*\"we\" + 0.009*\"data\" + 0.007*\"models\" + 0.007*\"model\" + 0.006*\"machine\" + 0.006*\"tasks\" + 0.006*\"the\" + 0.005*\"performance\"'), (7, '0.013*\"data\" + 0.012*\"learning\" + 0.006*\"image\" + 0.006*\"the\" + 0.006*\"time\" + 0.006*\"neural\" + 0.006*\"deep\" + 0.006*\"we\" + 0.006*\"in\" + 0.005*\"training\"'), (8, '0.009*\"learning\" + 0.007*\"in\" + 0.006*\"we\" + 0.005*\"matching\" + 0.004*\"reinforcement\" + 0.004*\"induced\" + 0.004*\"our\" + 0.004*\"also\" + 0.004*\"method\" + 0.003*\"rl\"'), (9, '0.010*\"we\" + 0.007*\"in\" + 0.006*\"the\" + 0.004*\"problem\" + 0.004*\"data\" + 0.003*\"language\" + 0.003*\"models\" + 0.003*\"also\" + 0.003*\"systems\" + 0.003*\"energy\"')]\n"
     ]
    }
   ],
   "source": [
    "# Get the topic distribution for each document\n",
    "for i, article in enumerate(article_summaries[0:10]):\n",
    "    print(f\"Article {i+1}: {lda.get_document_topics(corpus[i])}\")\n",
    "\n",
    "# Print the top words for each topic\n",
    "print(lda.print_topics())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dc3b14-bf4c-4636-a72a-8f4cd4335a3c",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0e3b4a5e-2437-4cbc-8269-1464d642f111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dataframe\n",
    "df = pd.DataFrame(columns=[\"article\", \"topic\", \"probability\"])\n",
    "\n",
    "# Loop over the articles and get the top 15 topics for each one\n",
    "for i, article in enumerate(article_summaries):\n",
    "    topics = lda.get_document_topics(corpus[i])\n",
    "    topics = sorted(topics, key=lambda x: x[1], reverse=True)[:15]\n",
    "    for topic in topics:\n",
    "        df = df.append({\"article\": i, \"topic\": topic[0], \"probability\": topic[1]}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "593d7794-4892-4c41-bdd2-3b30de67da55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>topic</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.547899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.444015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.650804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.266983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.077380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>644.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.033557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>645.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.994036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>646.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.496334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>646.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.351349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>646.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.145380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>917 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     article  topic  probability\n",
       "0        0.0    6.0     0.547899\n",
       "1        0.0    8.0     0.444015\n",
       "2        1.0    6.0     0.650804\n",
       "3        1.0    4.0     0.266983\n",
       "4        1.0    7.0     0.077380\n",
       "..       ...    ...          ...\n",
       "912    644.0    6.0     0.033557\n",
       "913    645.0    3.0     0.994036\n",
       "914    646.0    3.0     0.496334\n",
       "915    646.0    4.0     0.351349\n",
       "916    646.0    6.0     0.145380\n",
       "\n",
       "[917 rows x 3 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5880fa8b-36fc-4c04-9882-e305b4147b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of top words for each topic\n",
    "topics = lda.print_topics(num_words=5)\n",
    "\n",
    "# Create a dictionary that maps the topic numbers to the topic names\n",
    "topic_names = {}\n",
    "for topic in topics:\n",
    "    topic_num = topic[0]\n",
    "    split_w = [w for w in topic[1].split('+')]\n",
    "    topic_words = [w.split('*')[1] for w in split_w]\n",
    "    topic_name = \",\".join(topic_words)\n",
    "    topic_names[topic_num] = topic_name\n",
    "\n",
    "# Add a new column to the dataframe with the topic names\n",
    "df[\"topic_name\"] = df[\"topic\"].map(topic_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "70c86bcd-3431-462d-bc8f-189226fa0692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>topic</th>\n",
       "      <th>probability</th>\n",
       "      <th>topic_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.547899</td>\n",
       "      <td>\"automl\" ,\"learning\" ,\"we\" ,\"data\" ,\"models\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.444015</td>\n",
       "      <td>\"learning\" ,\"in\" ,\"we\" ,\"matching\" ,\"reinforce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.650804</td>\n",
       "      <td>\"automl\" ,\"learning\" ,\"we\" ,\"data\" ,\"models\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.266983</td>\n",
       "      <td>\"models\" ,\"model\" ,\"data\" ,\"we\" ,\"language\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.077380</td>\n",
       "      <td>\"data\" ,\"learning\" ,\"image\" ,\"the\" ,\"time\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>644.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.033557</td>\n",
       "      <td>\"automl\" ,\"learning\" ,\"we\" ,\"data\" ,\"models\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>645.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.994036</td>\n",
       "      <td>\"we\" ,\"the\" ,\"models\" ,\"this\" ,\"model\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>646.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.496334</td>\n",
       "      <td>\"we\" ,\"the\" ,\"models\" ,\"this\" ,\"model\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>646.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.351349</td>\n",
       "      <td>\"models\" ,\"model\" ,\"data\" ,\"we\" ,\"language\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>646.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.145380</td>\n",
       "      <td>\"automl\" ,\"learning\" ,\"we\" ,\"data\" ,\"models\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>917 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     article  topic  probability  \\\n",
       "0        0.0    6.0     0.547899   \n",
       "1        0.0    8.0     0.444015   \n",
       "2        1.0    6.0     0.650804   \n",
       "3        1.0    4.0     0.266983   \n",
       "4        1.0    7.0     0.077380   \n",
       "..       ...    ...          ...   \n",
       "912    644.0    6.0     0.033557   \n",
       "913    645.0    3.0     0.994036   \n",
       "914    646.0    3.0     0.496334   \n",
       "915    646.0    4.0     0.351349   \n",
       "916    646.0    6.0     0.145380   \n",
       "\n",
       "                                            topic_name  \n",
       "0         \"automl\" ,\"learning\" ,\"we\" ,\"data\" ,\"models\"  \n",
       "1    \"learning\" ,\"in\" ,\"we\" ,\"matching\" ,\"reinforce...  \n",
       "2         \"automl\" ,\"learning\" ,\"we\" ,\"data\" ,\"models\"  \n",
       "3          \"models\" ,\"model\" ,\"data\" ,\"we\" ,\"language\"  \n",
       "4           \"data\" ,\"learning\" ,\"image\" ,\"the\" ,\"time\"  \n",
       "..                                                 ...  \n",
       "912       \"automl\" ,\"learning\" ,\"we\" ,\"data\" ,\"models\"  \n",
       "913             \"we\" ,\"the\" ,\"models\" ,\"this\" ,\"model\"  \n",
       "914             \"we\" ,\"the\" ,\"models\" ,\"this\" ,\"model\"  \n",
       "915        \"models\" ,\"model\" ,\"data\" ,\"we\" ,\"language\"  \n",
       "916       \"automl\" ,\"learning\" ,\"we\" ,\"data\" ,\"models\"  \n",
       "\n",
       "[917 rows x 4 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a4950b-f171-4fe9-92ff-e956f39d0bef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "78951756-83b1-4196-b388-7912f8b6da0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'gensim' from 'pyLDAvis' (/Users/vatsalpatel/opt/miniconda3/envs/test_env/lib/python3.10/site-packages/pyLDAvis/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyLDAvis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gensim\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'gensim' from 'pyLDAvis' (/Users/vatsalpatel/opt/miniconda3/envs/test_env/lib/python3.10/site-packages/pyLDAvis/__init__.py)"
     ]
    }
   ],
   "source": [
    "from pyLDAvis import gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f6a96593-65bd-4b8c-bb02-b792967923b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyLDAvis.gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyLDAvis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgensim\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyLDAvis.gensim'"
     ]
    }
   ],
   "source": [
    "import pyLDAvis.gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c2d2c4-9599-4526-931c-7d620b7e678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4484e9-88d3-40af-b23b-039094483a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_vis = pyLDAvis.gensim.prepare(body_lda_model_25, body_corpus_25, dictionary=body_lda_model_25.id2word,mds='mmds',sort_topics=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874e4452-9f39-448f-8f07-767fd0951cbe",
   "metadata": {},
   "source": [
    "## Topic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7976dfa-92eb-4295-be69-7b3b7711a555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3195860-23f1-4434-897b-3dbcb7b34897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de1176bc-e340-4eba-af4f-76e2703b759e",
   "metadata": {},
   "source": [
    "## Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60e631f-88d5-441d-8c2a-719ec7916896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7125fa-d139-4cdc-9e01-e2b13a7b356b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a22604b1-0948-4a5c-9159-f140e60580ed",
   "metadata": {},
   "source": [
    "# Supervised Learning - Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9478edf1-f0a5-48ca-a192-a5f0d0148515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9662ca63-b0ec-47a9-a733-d09d9f8381ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef479b34-0487-4938-83f1-ea63aa3290b8",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbd9920-64df-400a-b73b-4afda59893e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba1bdc9-80a3-4d4d-b6ef-0427c956b763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec2a46b3-6781-497a-a8f9-6daa28f06827",
   "metadata": {},
   "source": [
    "# Supervised Learning - Multi-Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753a2a44-065d-4777-928b-103c726b913e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bc1389-a453-402f-9e2d-a085a62541cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb54da1a-e340-412a-a043-16f9a2160dc0",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
