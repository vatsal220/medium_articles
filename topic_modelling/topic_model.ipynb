{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8644bf09-042c-4b56-b4ba-9de0edb79459",
   "metadata": {},
   "source": [
    "# Supervised & Unsupervised Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6af3e56d-77d1-40ac-bdcc-538c21abf43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import string\n",
    "import unidecode\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from typing import List\n",
    "\n",
    "try:\n",
    "    from nltk.corpus import stopwords\n",
    "except:\n",
    "    import nltk\n",
    "    nltk.download('stopwords')\n",
    "finally:\n",
    "    from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e875103-ec29-4165-984e-ce2c4abb133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "queries = [\n",
    "    'automl', 'machinelearning', 'data', 'phyiscs','mathematics', 'recommendation system', 'nlp', 'neural networks'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afca02b4-3cc9-4bc5-9f1f-4c5a9e1e0166",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71fbc053-3bd7-4747-924b-7ce384ea417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_arxiv(queries: List[str], max_results: int = 100) -> pd.DataFrame:\n",
    "    '''\n",
    "    This function will search arxiv associated to a set of queries and store\n",
    "    the latest 10000 (max_results) associated to that search.\n",
    "    \n",
    "    params:\n",
    "        queries (List -> Str) : A list of strings containing keywords you want\n",
    "                                to search on Arxiv\n",
    "        max_results (Int) : The maximum number of results you want to see associated\n",
    "                            to your search. Default value is 1000, capped at 300000\n",
    "                            \n",
    "    returns:\n",
    "        This function will return a DataFrame holding the following columns associated\n",
    "        to the queries the user has passed. \n",
    "            `title`, `date`, `article_id`, `url`, `main_topic`, `all_topics`\n",
    "    \n",
    "    example:\n",
    "        research_df = search_arxiv(\n",
    "            queries = ['automl', 'recommender system', 'nlp', 'data science'],\n",
    "            max_results = 10000\n",
    "        )\n",
    "    '''\n",
    "    d = []\n",
    "    searches = []\n",
    "    # hitting the API\n",
    "    for query in queries:\n",
    "        search = arxiv.Search(\n",
    "          query = query,\n",
    "          max_results = max_results,\n",
    "          sort_by = arxiv.SortCriterion.SubmittedDate,\n",
    "          sort_order = arxiv.SortOrder.Descending\n",
    "        )\n",
    "        searches.append(search)\n",
    "    \n",
    "    # Converting search result into df\n",
    "    for search in searches:\n",
    "        for res in search.results():\n",
    "            data = {\n",
    "                'title' : res.title,\n",
    "                'date' : res.published,\n",
    "                'article_id' : res.entry_id,\n",
    "                'url' : res.pdf_url,\n",
    "                'main_topic' : res.primary_category,\n",
    "                'summary' : res.summary,\n",
    "                'all_topics' : res.categories,\n",
    "                'authors' : res.authors\n",
    "            }\n",
    "            d.append(data)\n",
    "        \n",
    "    d = pd.DataFrame(d)\n",
    "    d['year'] = pd.DatetimeIndex(d['date']).year\n",
    "    \n",
    "    # change article id from url to integer\n",
    "    unique_article_ids = d.article_id.unique()\n",
    "    article_mapping = {art:idx for idx,art in enumerate(unique_article_ids)}\n",
    "    d['article_id'] = d['article_id'].map(article_mapping)\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0f6b598-b93d-405a-8d44-f8c02cde8ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(648, 9)\n"
     ]
    }
   ],
   "source": [
    "# fetch data from arXiv\n",
    "research_df = search_arxiv(\n",
    "    queries = queries,\n",
    "    max_results = 100\n",
    ")\n",
    "print(research_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "238f0c53-f268-44f5-be58-81b9017f1396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>article_id</th>\n",
       "      <th>url</th>\n",
       "      <th>main_topic</th>\n",
       "      <th>summary</th>\n",
       "      <th>all_topics</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Improvement of Computational Performance of Ev...</td>\n",
       "      <td>2023-01-12 15:59:04+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>http://arxiv.org/pdf/2301.05102v1</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>Resource-intensive computations are a major fa...</td>\n",
       "      <td>[cs.LG, cs.NE, cs.PF]</td>\n",
       "      <td>[Nikolay O. Nikitin, Sergey Teryoshkin, Valeri...</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data-driven photometric redshift estimation fr...</td>\n",
       "      <td>2022-12-30 13:01:41+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>http://arxiv.org/pdf/2212.14668v1</td>\n",
       "      <td>astro-ph.IM</td>\n",
       "      <td>Redshift measurement has always been a constan...</td>\n",
       "      <td>[astro-ph.IM, astro-ph.CO]</td>\n",
       "      <td>[Felipe M F de Oliveira, Marcelo Vargas dos Sa...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Multi-objective Tree-structured Parzen Estimat...</td>\n",
       "      <td>2022-12-13 17:33:02+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>http://arxiv.org/pdf/2212.06751v1</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>Hyperparameter optimization (HPO) is essential...</td>\n",
       "      <td>[cs.LG, cs.AI]</td>\n",
       "      <td>[Shuhei Watanabe, Noow Awad, Masaki Onishi, Fr...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POPNASv3: a Pareto-Optimal Neural Architecture...</td>\n",
       "      <td>2022-12-13 17:14:14+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>http://arxiv.org/pdf/2212.06735v1</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>The automated machine learning (AutoML) field ...</td>\n",
       "      <td>[cs.LG, cs.AI, cs.CV, cs.NE]</td>\n",
       "      <td>[Andrea Falanti, Eugenio Lomurno, Danilo Ardag...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AutoPINN: When AutoML Meets Physics-Informed N...</td>\n",
       "      <td>2022-12-08 03:44:08+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>http://arxiv.org/pdf/2212.04058v1</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>Physics-Informed Neural Networks (PINNs) have ...</td>\n",
       "      <td>[cs.LG, cs.AI]</td>\n",
       "      <td>[Xinle Wu, Dalin Zhang, Miao Zhang, Chenjuan G...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Improvement of Computational Performance of Ev...   \n",
       "1  Data-driven photometric redshift estimation fr...   \n",
       "2  Multi-objective Tree-structured Parzen Estimat...   \n",
       "3  POPNASv3: a Pareto-Optimal Neural Architecture...   \n",
       "4  AutoPINN: When AutoML Meets Physics-Informed N...   \n",
       "\n",
       "                       date  article_id                                url  \\\n",
       "0 2023-01-12 15:59:04+00:00           0  http://arxiv.org/pdf/2301.05102v1   \n",
       "1 2022-12-30 13:01:41+00:00           1  http://arxiv.org/pdf/2212.14668v1   \n",
       "2 2022-12-13 17:33:02+00:00           2  http://arxiv.org/pdf/2212.06751v1   \n",
       "3 2022-12-13 17:14:14+00:00           3  http://arxiv.org/pdf/2212.06735v1   \n",
       "4 2022-12-08 03:44:08+00:00           4  http://arxiv.org/pdf/2212.04058v1   \n",
       "\n",
       "    main_topic                                            summary  \\\n",
       "0        cs.LG  Resource-intensive computations are a major fa...   \n",
       "1  astro-ph.IM  Redshift measurement has always been a constan...   \n",
       "2        cs.LG  Hyperparameter optimization (HPO) is essential...   \n",
       "3        cs.LG  The automated machine learning (AutoML) field ...   \n",
       "4        cs.LG  Physics-Informed Neural Networks (PINNs) have ...   \n",
       "\n",
       "                     all_topics  \\\n",
       "0         [cs.LG, cs.NE, cs.PF]   \n",
       "1    [astro-ph.IM, astro-ph.CO]   \n",
       "2                [cs.LG, cs.AI]   \n",
       "3  [cs.LG, cs.AI, cs.CV, cs.NE]   \n",
       "4                [cs.LG, cs.AI]   \n",
       "\n",
       "                                             authors  year  \n",
       "0  [Nikolay O. Nikitin, Sergey Teryoshkin, Valeri...  2023  \n",
       "1  [Felipe M F de Oliveira, Marcelo Vargas dos Sa...  2022  \n",
       "2  [Shuhei Watanabe, Noow Awad, Masaki Onishi, Fr...  2022  \n",
       "3  [Andrea Falanti, Eugenio Lomurno, Danilo Ardag...  2022  \n",
       "4  [Xinle Wu, Dalin Zhang, Miao Zhang, Chenjuan G...  2022  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f41b0a-4de7-46c3-88f3-a62d24c4a539",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95118db5-8358-46db-ad38-90a67f6550a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text: str, sw: List[str] = stopwords) -> str:\n",
    "    '''\n",
    "    This function will remove stopwords from the text\n",
    "    \n",
    "    Args:\n",
    "        text: String of data you want to remove stopwords from\n",
    "        sw: List of strings indicating the list of stopwords\n",
    "        \n",
    "    Returns:\n",
    "        The input string with the stopwords removed.\n",
    "    '''\n",
    "    return ' '.join([word for word in text.split() if word not in stopwords.words('english')])\n",
    "    \n",
    "def remove_punctuation(text: str, punct: str = string.punctuation) -> str:\n",
    "    '''\n",
    "    This function will remove punctuations from the text.\n",
    "    \n",
    "    Args:\n",
    "        text: String of data you want to remove punctuations from\n",
    "        punct: String of punctuations\n",
    "    \n",
    "    Returns:\n",
    "        The input string with the punctuations removed.\n",
    "    '''\n",
    "    cleaned_text = ''.join([char for char in text if char not in punct])\n",
    "    return cleaned_text\n",
    "    \n",
    "def unicode(text: str) -> str:\n",
    "    '''\n",
    "    This function will make all the data unicoded. Meaning Â -> A\n",
    "    \n",
    "    Args:\n",
    "        text: String of data you want to unicode\n",
    "    \n",
    "    Returns:\n",
    "        The input string unicoded.\n",
    "    '''\n",
    "    return unidecode.unidecode(text)\n",
    "    \n",
    "def clean(text: str) -> str:\n",
    "    '''\n",
    "    This method will clean the input text through unidecoding and stopword and punctuation \n",
    "    removal.\n",
    "    \n",
    "    Args:\n",
    "        text: String indicating the body of text you want to clean\n",
    "    \n",
    "    Returns:\n",
    "        A string corresponding to the cleaned version of the input string.\n",
    "    '''\n",
    "    text = unicode(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "717eb255-71c3-4287-9175-ea652410148d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.76 s, sys: 715 ms, total: 4.48 s\n",
      "Wall time: 4.48 s\n"
     ]
    }
   ],
   "source": [
    "%time research_df['cleaned_summary'] = research_df['summary'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a47deda2-19b0-493a-afd5-8d5824149863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>article_id</th>\n",
       "      <th>url</th>\n",
       "      <th>main_topic</th>\n",
       "      <th>summary</th>\n",
       "      <th>all_topics</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "      <th>cleaned_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Improvement of Computational Performance of Ev...</td>\n",
       "      <td>2023-01-12 15:59:04+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>http://arxiv.org/pdf/2301.05102v1</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>Resource-intensive computations are a major fa...</td>\n",
       "      <td>[cs.LG, cs.NE, cs.PF]</td>\n",
       "      <td>[Nikolay O. Nikitin, Sergey Teryoshkin, Valeri...</td>\n",
       "      <td>2023</td>\n",
       "      <td>resourceintensive computations major factor li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data-driven photometric redshift estimation fr...</td>\n",
       "      <td>2022-12-30 13:01:41+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>http://arxiv.org/pdf/2212.14668v1</td>\n",
       "      <td>astro-ph.IM</td>\n",
       "      <td>Redshift measurement has always been a constan...</td>\n",
       "      <td>[astro-ph.IM, astro-ph.CO]</td>\n",
       "      <td>[Felipe M F de Oliveira, Marcelo Vargas dos Sa...</td>\n",
       "      <td>2022</td>\n",
       "      <td>redshift measurement always constant need mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Multi-objective Tree-structured Parzen Estimat...</td>\n",
       "      <td>2022-12-13 17:33:02+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>http://arxiv.org/pdf/2212.06751v1</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>Hyperparameter optimization (HPO) is essential...</td>\n",
       "      <td>[cs.LG, cs.AI]</td>\n",
       "      <td>[Shuhei Watanabe, Noow Awad, Masaki Onishi, Fr...</td>\n",
       "      <td>2022</td>\n",
       "      <td>hyperparameter optimization hpo essential bett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POPNASv3: a Pareto-Optimal Neural Architecture...</td>\n",
       "      <td>2022-12-13 17:14:14+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>http://arxiv.org/pdf/2212.06735v1</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>The automated machine learning (AutoML) field ...</td>\n",
       "      <td>[cs.LG, cs.AI, cs.CV, cs.NE]</td>\n",
       "      <td>[Andrea Falanti, Eugenio Lomurno, Danilo Ardag...</td>\n",
       "      <td>2022</td>\n",
       "      <td>the automated machine learning automl field be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AutoPINN: When AutoML Meets Physics-Informed N...</td>\n",
       "      <td>2022-12-08 03:44:08+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>http://arxiv.org/pdf/2212.04058v1</td>\n",
       "      <td>cs.LG</td>\n",
       "      <td>Physics-Informed Neural Networks (PINNs) have ...</td>\n",
       "      <td>[cs.LG, cs.AI]</td>\n",
       "      <td>[Xinle Wu, Dalin Zhang, Miao Zhang, Chenjuan G...</td>\n",
       "      <td>2022</td>\n",
       "      <td>physicsinformed neural networks pinns recently...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Improvement of Computational Performance of Ev...   \n",
       "1  Data-driven photometric redshift estimation fr...   \n",
       "2  Multi-objective Tree-structured Parzen Estimat...   \n",
       "3  POPNASv3: a Pareto-Optimal Neural Architecture...   \n",
       "4  AutoPINN: When AutoML Meets Physics-Informed N...   \n",
       "\n",
       "                       date  article_id                                url  \\\n",
       "0 2023-01-12 15:59:04+00:00           0  http://arxiv.org/pdf/2301.05102v1   \n",
       "1 2022-12-30 13:01:41+00:00           1  http://arxiv.org/pdf/2212.14668v1   \n",
       "2 2022-12-13 17:33:02+00:00           2  http://arxiv.org/pdf/2212.06751v1   \n",
       "3 2022-12-13 17:14:14+00:00           3  http://arxiv.org/pdf/2212.06735v1   \n",
       "4 2022-12-08 03:44:08+00:00           4  http://arxiv.org/pdf/2212.04058v1   \n",
       "\n",
       "    main_topic                                            summary  \\\n",
       "0        cs.LG  Resource-intensive computations are a major fa...   \n",
       "1  astro-ph.IM  Redshift measurement has always been a constan...   \n",
       "2        cs.LG  Hyperparameter optimization (HPO) is essential...   \n",
       "3        cs.LG  The automated machine learning (AutoML) field ...   \n",
       "4        cs.LG  Physics-Informed Neural Networks (PINNs) have ...   \n",
       "\n",
       "                     all_topics  \\\n",
       "0         [cs.LG, cs.NE, cs.PF]   \n",
       "1    [astro-ph.IM, astro-ph.CO]   \n",
       "2                [cs.LG, cs.AI]   \n",
       "3  [cs.LG, cs.AI, cs.CV, cs.NE]   \n",
       "4                [cs.LG, cs.AI]   \n",
       "\n",
       "                                             authors  year  \\\n",
       "0  [Nikolay O. Nikitin, Sergey Teryoshkin, Valeri...  2023   \n",
       "1  [Felipe M F de Oliveira, Marcelo Vargas dos Sa...  2022   \n",
       "2  [Shuhei Watanabe, Noow Awad, Masaki Onishi, Fr...  2022   \n",
       "3  [Andrea Falanti, Eugenio Lomurno, Danilo Ardag...  2022   \n",
       "4  [Xinle Wu, Dalin Zhang, Miao Zhang, Chenjuan G...  2022   \n",
       "\n",
       "                                     cleaned_summary  \n",
       "0  resourceintensive computations major factor li...  \n",
       "1  redshift measurement always constant need mode...  \n",
       "2  hyperparameter optimization hpo essential bett...  \n",
       "3  the automated machine learning automl field be...  \n",
       "4  physicsinformed neural networks pinns recently...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffad1e0-9a4d-49b1-b4bb-6c3cf9a64d0e",
   "metadata": {},
   "source": [
    "# Unsupervised Learning - LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37bdbc25-6cc5-4acb-9f4d-125e0c805c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from gensim import models, corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ae6004d-a466-4409-83b4-d00522bec283",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_summaries = research_df['cleaned_summary'].values\n",
    "article_summaries = [[word for word in nltk.word_tokenize(article)] for article in article_summaries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "050c6c29-7816-4899-9c17-bff976c525d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of all the words in the dataset\n",
    "dictionary = corpora.Dictionary(article_summaries)\n",
    "\n",
    "# Create a corpus\n",
    "corpus = [dictionary.doc2bow(article) for article in article_summaries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f01a879-54ba-4141-88ab-1c97c6d261e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.62 s, sys: 39.2 ms, total: 4.66 s\n",
      "Wall time: 4.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create an LDA model\n",
    "lda = models.LdaModel(corpus, num_topics=10, id2word=dictionary, passes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f41f910-8aba-4813-9223-55ecfdd6fef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article 1: [(3, 0.46642175), (4, 0.23049094), (6, 0.29011086)]\n",
      "Article 2: [(3, 0.9944393)]\n",
      "Article 3: [(3, 0.42782903), (6, 0.43481714), (9, 0.13027664)]\n",
      "Article 4: [(3, 0.30521417), (5, 0.18022123), (9, 0.5097325)]\n",
      "Article 5: [(3, 0.33438456), (6, 0.03671778), (7, 0.4607561), (9, 0.16465013)]\n",
      "Article 6: [(0, 0.08745317), (3, 0.73005104), (9, 0.17600614)]\n",
      "Article 7: [(1, 0.7006785), (9, 0.2929171)]\n",
      "Article 8: [(3, 0.48065946), (7, 0.51125216)]\n",
      "Article 9: [(2, 0.7006705), (3, 0.05207039), (9, 0.24218127)]\n",
      "Article 10: [(3, 0.994794)]\n",
      "[(0, '0.011*\"we\" + 0.005*\"models\" + 0.005*\"the\" + 0.004*\"two\" + 0.004*\"in\" + 0.004*\"methods\" + 0.004*\"this\" + 0.004*\"language\" + 0.004*\"show\" + 0.004*\"data\"'), (1, '0.008*\"time\" + 0.005*\"data\" + 0.005*\"the\" + 0.005*\"model\" + 0.005*\"in\" + 0.004*\"this\" + 0.004*\"work\" + 0.003*\"proposed\" + 0.003*\"dynamics\" + 0.003*\"we\"'), (2, '0.014*\"we\" + 0.007*\"models\" + 0.006*\"language\" + 0.006*\"in\" + 0.005*\"model\" + 0.005*\"system\" + 0.005*\"learning\" + 0.005*\"using\" + 0.005*\"tasks\" + 0.004*\"show\"'), (3, '0.017*\"data\" + 0.016*\"learning\" + 0.016*\"automl\" + 0.011*\"models\" + 0.010*\"model\" + 0.009*\"machine\" + 0.006*\"ml\" + 0.006*\"performance\" + 0.006*\"we\" + 0.005*\"automated\"'), (4, '0.011*\"the\" + 0.006*\"energy\" + 0.006*\"quantum\" + 0.005*\"we\" + 0.005*\"proposed\" + 0.005*\"networks\" + 0.005*\"in\" + 0.004*\"control\" + 0.004*\"method\" + 0.004*\"neural\"'), (5, '0.009*\"network\" + 0.008*\"we\" + 0.007*\"networks\" + 0.007*\"model\" + 0.006*\"in\" + 0.005*\"the\" + 0.005*\"models\" + 0.004*\"show\" + 0.004*\"data\" + 0.004*\"using\"'), (6, '0.010*\"we\" + 0.008*\"the\" + 0.005*\"in\" + 0.004*\"new\" + 0.004*\"systems\" + 0.003*\"stars\" + 0.003*\"using\" + 0.003*\"results\" + 0.003*\"method\" + 0.003*\"neural\"'), (7, '0.009*\"data\" + 0.008*\"we\" + 0.007*\"the\" + 0.005*\"systems\" + 0.004*\"this\" + 0.004*\"in\" + 0.003*\"used\" + 0.003*\"quantum\" + 0.003*\"analysis\" + 0.003*\"use\"'), (8, '0.011*\"the\" + 0.011*\"we\" + 0.005*\"in\" + 0.005*\"data\" + 0.005*\"results\" + 0.004*\"model\" + 0.004*\"show\" + 0.003*\"also\" + 0.003*\"use\" + 0.003*\"paper\"'), (9, '0.009*\"we\" + 0.007*\"learning\" + 0.007*\"neural\" + 0.007*\"models\" + 0.006*\"in\" + 0.006*\"search\" + 0.006*\"data\" + 0.005*\"the\" + 0.005*\"nas\" + 0.005*\"performance\"')]\n"
     ]
    }
   ],
   "source": [
    "# Get the topic distribution for each document\n",
    "for i, article in enumerate(article_summaries[0:10]):\n",
    "    print(f\"Article {i+1}: {lda.get_document_topics(corpus[i])}\")\n",
    "\n",
    "# Print the top words for each topic\n",
    "print(lda.print_topics())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dc3b14-bf4c-4636-a72a-8f4cd4335a3c",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e3b4a5e-2437-4cbc-8269-1464d642f111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dataframe\n",
    "df = pd.DataFrame(columns=[\"article\", \"topic\", \"probability\"])\n",
    "\n",
    "# Loop over the articles and get the top 15 topics for each one\n",
    "for i, article in enumerate(article_summaries):\n",
    "    topics = lda.get_document_topics(corpus[i])\n",
    "    topics = sorted(topics, key=lambda x: x[1], reverse=True)[:15]\n",
    "    for topic in topics:\n",
    "        df = df.append({\"article\": i, \"topic\": topic[0], \"probability\": topic[1]}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "593d7794-4892-4c41-bdd2-3b30de67da55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>topic</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.466409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.290113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.230501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.994439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.434814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>643.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.992965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>644.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.992618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>645.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.994226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>646.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.993177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>647.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>907 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     article  topic  probability\n",
       "0        0.0    3.0     0.466409\n",
       "1        0.0    6.0     0.290113\n",
       "2        0.0    4.0     0.230501\n",
       "3        1.0    3.0     0.994439\n",
       "4        2.0    6.0     0.434814\n",
       "..       ...    ...          ...\n",
       "902    643.0    9.0     0.992965\n",
       "903    644.0    3.0     0.992618\n",
       "904    645.0    3.0     0.994226\n",
       "905    646.0    8.0     0.993177\n",
       "906    647.0    1.0     0.993280\n",
       "\n",
       "[907 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5880fa8b-36fc-4c04-9882-e305b4147b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of top words for each topic\n",
    "topics = lda.print_topics(num_words=5)\n",
    "\n",
    "# Create a dictionary that maps the topic numbers to the topic names\n",
    "topic_names = {}\n",
    "for topic in topics:\n",
    "    topic_num = topic[0]\n",
    "    split_w = [w for w in topic[1].split('+')]\n",
    "    topic_words = [w.split('*')[1] for w in split_w]\n",
    "    topic_name = \",\".join(topic_words)\n",
    "    topic_names[topic_num] = topic_name\n",
    "\n",
    "# Add a new column to the dataframe with the topic names\n",
    "df[\"topic_name\"] = df[\"topic\"].map(topic_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70c86bcd-3431-462d-bc8f-189226fa0692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    169\n",
       "9.0    126\n",
       "2.0    115\n",
       "8.0     91\n",
       "4.0     86\n",
       "7.0     75\n",
       "0.0     74\n",
       "5.0     71\n",
       "6.0     60\n",
       "1.0     40\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a4950b-f171-4fe9-92ff-e956f39d0bef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd8bbe6-42f2-4412-a465-b16dd853c2d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eeff1ae2-9c04-4af8-abce-615180a95754",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bce4723-d909-414d-8e04-9985d5fd8e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde228e8-23a9-422f-afd3-1b2b39a61b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc40cd5-8c47-4b25-958d-67a345f10f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "874e4452-9f39-448f-8f07-767fd0951cbe",
   "metadata": {},
   "source": [
    "## Topic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7976dfa-92eb-4295-be69-7b3b7711a555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3195860-23f1-4434-897b-3dbcb7b34897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a22604b1-0948-4a5c-9159-f140e60580ed",
   "metadata": {},
   "source": [
    "# Supervised Learning - Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9478edf1-f0a5-48ca-a192-a5f0d0148515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9662ca63-b0ec-47a9-a733-d09d9f8381ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef479b34-0487-4938-83f1-ea63aa3290b8",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbd9920-64df-400a-b73b-4afda59893e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba1bdc9-80a3-4d4d-b6ef-0427c956b763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec2a46b3-6781-497a-a8f9-6daa28f06827",
   "metadata": {},
   "source": [
    "# Supervised Learning - Multi-Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753a2a44-065d-4777-928b-103c726b913e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bc1389-a453-402f-9e2d-a085a62541cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb54da1a-e340-412a-a043-16f9a2160dc0",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
